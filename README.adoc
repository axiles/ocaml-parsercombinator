// vim:filetype=asciidoc expandtab spell spelllang=en ts=2 sw=2
= Homegrown Parser Combinators with error detection
rixed@happyleptic.org
v0.1, 2015-10-27
:toc:
:numbered:
:icons:
:lang: en
:encoding: utf-8

== What is this?

This document describe the implementation of a library to perform text
parsing according to a technique called
https://en.wikipedia.org/wiki/Parser_combinator[parser combinators] because the
parser for a given grammar is build combining simpler parsers. This technique
is fashionable although old and slow because it is simple and permissive.

This is also an example of literate programming; in case the notations used in
this document are unclear you can read about them in
http://rixed.github.io/portia/notations.html[this document].

== Requirements

=== Parsing perl as deep as possible without executing it

This is our ultimate objective, that drives all of the following requirements.

=== Parsing recursively

Perl has +eval+ on strings. Therefore we do not want to stop parsing a soon as
we reach a string literal if it's (or could be) passed to the +eval+ function.

=== Parsing with gaps

For the same reason, we want to be able to parse as much as possible of a code
string even if we are missing some part of it.

=== Best effort

It will not always be possible to know for sure the type of all symbols. In
that case we want to present all possible alternatives as the result, rather
than stopping the parse or selecting the most probable one.

=== Error detection?

The code that will be sent to this parser will already be valid most of the time..
Therefore, the error reporting need not detect typos or other user error.
Essentially, we need error reports merely to debug the parser itself. So error
reports must _only_ include the (best) partial result(s) and why they failed.

It is very unfortunate though that even in those favorable circumstances
detecting what is the best attempt in order to explain why this one failed
seems to require the same expensive error detection techniques that to detect
user typos.

Indeed, the only way to detect the best attempt is: should this parser had
behaved differently then the whole outcome would have been very different. In
other words, should this parser accept this input as a valid token then we
would have eventually parsed the whole input.

It is hard to think of any trivial trick to make it less awfully explosive that
it sounds, beyond constraining the exploratory search within an 'error budget'.

Many of those ideas come from
http://www.staff.science.uu.nl/~swier101/Papers/1999/SofSem99.pdf[Fast, Error
Correcting Parser Combinators: A Short Tutorial], a XX^th^ century paper.

=== Parser Combinators

Perl does not bow to any rigid formal rule. Parser combinators are appealing
because they make it possible to add new valid constructs without rethinking
the whole grammar.  In addition, they make significantly easier to achieve the
previous objectives.

== The type of the parser

To be clearer, let's write down the usual type of a parser used with
combinators, written in ML:

.Typical parser type
[source,ml]
----
type ('a, 'b) result = 'b * 'a list
type ('a, 'b) parser = 'a list -> ('a, 'b) result list
----

Which reads like this: Calling α the type of the input tokens and β the type
of the parsed inputs, a parser is a function that takes a list of α and
returns a list of pairs composed of a β and a list of α, with the assumptions
that the input list of α is the input stream of tokens to be parsed and that
each output pair are a possible solution, composed of the result and the
remaining list of token to parse. Ideally, a successful top level parser will
thus return a list composed of a single pair (non ambiguity of the outcome)
made of the final result and an empty list (no more input to be parsed). And
when the parser fails to find any way to parse the input it returns a
minimally informative empty list.

Introducing the error budget changes this somewhat: we will try to
artificially force the failing parsers to succeed in order to peek into the
future and try to locate where a change would cause the parsing to succeed.
This means that each individual result must be accompanied by a description of
the (few) changes required to reach that point:

.Parser type with error budget
[source,ml]
----
type ('a, 'b) result = 'b * Corrections.t * 'a list
type ('a, 'b) parser =
  Corrections.t -> 'a list -> ('a, 'b) result list
----

Before looking closer to this new +Corrections.t+ type that would encode the corrections
we must question the usage of a list of results as the return type. First, of
course, a list if over-specified since the order of the possible result is not
important; what we really want here is a set and we use a list only because it
makes our code more terse. But more importantly, one may think that it is not
enough to return an empty list in case of failure since we may also want to
force artificially the failure of a parser; a possibility that we have
dismissed without giving it proper consideration. Indeed, failing to recognize
one form may enable a following parser to succeed. Consider for instance a C++
like language with the erroneous input:

----
class form;
for x = new form(...);
----

Obviously the intent was to write +form x = ...+. Once the parser have
accepted the keyword +for+ as valid without questioning it then it is likely
that the error message porting on what follows will be hard to understand. On
another hand, if the parser also tried to force the failure of the keyword
parser in this location then it will notice that everything would parse
properly henceforth, suggesting a better error message.

The price to pay for testing the failure of successful parsers is obviously high,
though, and not only because of the additional time spent. Returning error
descriptions alongside failures forces us to give up the elegant list of
result as the main return type (indeed, the empty list is not enough any more
to denote failure since we also want to return the updated errors description).

It seems that only in the case of the exclusive alternative this problem will
arise. Should we decide not to implement such a combinator, then the the above
example ``either a keyword or a variable name that is not a keyword'' could
still be written with inclusive alternative at the price of a redundant check:
+is_keyword OR (is_name AND (check (NOT is_keyword))+. In this case we could
explore the failure of the +NOT is_keyword+ check and will find that should
+for+ be a valid variable name then the input would be valid, which will make
a good enough error reporting.

So we will not implement exclusive alternative and will instead explore forced
success of the +check+ parser.

Now, what's this +Corrections.t+ type?

To be able to build a useful error message we must point at the position in
the original stream of tokens where some change had to be made in order to
parse the input stream of tokens (if not in full at least more than without
that change). Recording a position in the original input stream of tokens is
less trivial than it sounds because we are combining the parsers, and one of
the way to combine parsers is to run a parser on the results of another one,
therefore loosing track of the position in the original stream. For generality
let's introduce a new type ɣ to denote a position (could be merely the integer
offset in the original stream or a more elaborate line and column number, or
anything) and let's assume we read from the original stream not only the
tokens but also the positions. And since we are reading the positions from the
input stream we need to introduce a special value for representing the end of
input, that we will call +EOF+:

.Corrections: the type for positions
[source,ml]
----
type 'c position = Coord of 'c | EOF
----

So we need to record all changes that have already occurred (what and where)
and how many changes we are still allowed to do. The ``What'' is limited to
any string description of the parser that we forced to succeed.

.Corrections: type
[source,ml]
----
type 'c t = ('c position * string) BoundedSet.t
----

where +BoundedSet+ is an unordered container with a maximum capacity (the
maximum amount of changes allowed) and which API will become clearer as we
encounter the few required functions.

Trivially, to add an error at position +pos+ to the correction list, with
message +msg+:

.Corrections: recording a change
[source,ml]
----
let change_at corr pos msg =
  BoundedSet.add corr (pos, msg)
----

Now that we know what corrections look like and that we have to read the
positions alongside the tokens from the input stream, we can finally write the
definitive parser type:

.Parsers: final type
[source,ml]
----
type ('a, 'b, 'c) result = 'b * ('c Corrections.t) * ('a * 'c) list
type ('a, 'b, 'c) t =
  'c Corrections.t -> ('a * 'c) list -> ('a, 'b, 'c) result list
----

It is sometime unfortunate that OCaml compiler do not preserve the type
variable names throughout a program. In this document though we will stick
with those:

- α (+'a+) stands for the type of input tokens,
- β (+'b+) stands for the type of parsing results,
- ɣ (+'c+) stands for the type of positions in the input stream.

== Base parsers (to be combined)

=== Fail, Return and check.

The simplest parsers that does nothing are +return+ and +fail+. They do not
consume anything from the input but merely return a single result or no result
at all. Given our parser type, here are their implementations:

.Parsers: fail
[source,ml]
----
let fail _corr _unp = []
----

.Parsers: return
[source,ml]
----
let return x corr rest = [x, corr, rest]
----

Those two first parsers perform no type of error detection at all.  But many
other parsers will have to either terminate parsing abruptly (with +fail+) or
add a change to the correction list and proceed, if the error budget is not
exhausted already. We will abstract this in a +fail_or_maybe_not+ function:

.Parsers: fail with success exploration
[source,ml]
----
open Batteries
open Corrections

let fail_or_maybe_not msg x ?pos corr rest =
  let pos = Option.default_delayed (fun () -> next_position rest) pos in
  if BoundedSet.is_full corr then []  (* no more errors permitted so fail for real *)
  else [x, change_at corr pos msg, rest]
----

with:

.Corrections: next_position in a (possibly empty) stream
[source,ml]
----
let next_position = function
  | [] -> EOF
  | (_tok, pos)::_ -> Coord pos
----

Another parser that does not consume any input is the +check+ parser that we
have mentioned earlier. It is actually a combinator since it takes another
parser as parameter. It checks that the given parser succeed but then return
the input stream unchanged (with a +unit+ result). The only thing interesting
is that it explores forcing a success in case the check fails.

.Parsers: check
[source,ml]
----
let check msg p corr rest =
  match p corr rest with
  | [] -> fail_or_maybe_not msg () corr rest
  | _ -> return () corr rest
----

Another parser that will prove useful (despite contributing no value to the
result) especially in coordination with +check+ is the negation:

.Parsers: negation
[source,ml]
----
let not p corr rest =
  match p corr rest with
  | [] -> return () corr rest
  | _ -> fail_or_maybe_not "not" () corr rest
----

So that we could write +check msg (not p)+.

=== Tests

It's is important to have a test infrastructure in place before it's needed.
Given literate programing allows us to mix code and tests at ease we do not
need to get this feature from such a tool as
https://github.com/vincent-hugot/iTeML[qtest] and will use
http://ounit.forge.ocamlcore.org/api-ounit/index.html[oUnit] directly.

Supposing for now that we have all the required printers we can set up a
satisfying environment for tests:

.test: the stage.
[source,ml]
----
open Batteries
open OUnit2
open Corrections
open Parsers
(* ...other tested modules... *)

let input_of_string s =
  let rec loop n tl =
    if n < 0 then tl else
    loop (n-1) ((s.[n], n) :: tl) in
  loop (String.length s - 1) []

let max_changes = 3
let corr = BoundedSet.make max_changes
let correction_at pos msg =
  let corr = BoundedSet.make max_changes in
  change_at corr pos msg

let no_corr = BoundedSet.make 0
let rest = input_of_string "glop glop pas glop"
let no_input = []

(* ...other global functions or types for testing... *)

let uniq = function
  | [x, _, _] -> Some x
  | _ -> None

(* version of assert_equal specialized for parser results *)
let assert_same_results ?msg print_output exp actual =
  let print_input = Char.print in
  let print_coord fmt c = Printf.fprintf fmt "offset %d" c in
  let result_printer = print_result print_input print_coord print_output in
  let results_printer = List.print result_printer in
  (* OUnit really should have a assert_same_elements *)
  assert_equal ~printer:(IO.to_string results_printer) ?msg
    (exp |> List.sort compare)
    (actual |> List.sort compare)

let test_suite =
  "tests" >:::
    [ (* ...tests... *) ]

let () =
  run_test_tt_main test_suite
----

That we can test with simple tests for +return+ and +fail+ (which really
does not cause too much worries):

.tests
[source,ml]
----
"return succeed" >:: (
  fun _ctx ->
    assert_same_results Int.print
      [42, no_corr, rest]
      (return 42 no_corr rest)
) ;
"return succeed even at EOF" >:: (
  fun _ctx ->
    assert_same_results Int.print
      [42, no_corr, []]
      (return 42 no_corr no_input)
) ;
"fail fails" >:: (
  fun _ctx ->
    assert_same_results Int.print
      []
      (fail no_corr rest)
) ;
"fail fails even at EOF" >:: (
  fun _ctx ->
    assert_same_results Int.print
      []
      (fail no_corr no_input)
) ;
----

=== Checking for end of stream

Another very useful and basic parser is the one that succeeds on EOF and fails
everywhere else. It is useful to check that the input stream have been consumed
entirely by the preceding parsers).

We may not want tp engage in error detection in this parser: mimicking success
imply pretending the stream stops there, but most input streams could be
trivially declared valid if the stream is cut short (empty string is often
valid for instance). In case of spurious input tokens at the end the error
message shouldn't the error message be trivial enough already? That's
forgetting that we are going to combine parsers, and ``end of stream'' does not
necessarily mean ``end of outer input stream''. It could for instance means the
``end of lines'' in a message header or the ``end of initializers'' in an
initializer list.

We will therefore explore forcing the success of this parser, which implies
cutting the unparsed stream when mimicking success:

.Parsers: checking for EOF
[source,ml]
----
let eof msg corr = function
  | [] -> return () corr []
  | _ as rest ->
    fail_or_maybe_not
      ("spurious "^msg) () 
      ~pos:(next_position rest) corr [] (* <1> *)
----

<1>: Here we will restart with +rest = []+. That's the only case when forcing
success also alters the input stream.

And the accompanying test:

.tests
[source,ml]
----
"eof succeed" >:: (
  fun _ctx ->
    assert_same_results Unit.print
      [(), no_corr, []]
      (eof "char" no_corr no_input)
) ;
"eof fails" >:: (
  fun _ctx ->
    assert_same_results Unit.print
      []
      (eof "char" no_corr rest)
) ;
"eof suggests truncation" >:: (
  fun _ctx ->
    assert_same_results Unit.print
      [(), correction_at (Coord 0) "spurious char", []]
      (eof "char" corr rest)
) ;
----

=== First non trivial parser

The more general of parsers that do consume some input is the +cond+ parser,
which tries to recognize a condition on the next token (for instance that it
is equal to a given value). So +cond+ is a function that takes a predicate on
token and returns a parser that, when given this token, returns it (and
consumes it), or otherwise fails (with a message describing what it was
looking for, in case we have to build an error message for that step later
on).

Now that we know the type, writing the code is rather easy:

.Parsers: the cond parser
[source,ml]
----
let cond msg f x corr rest =
  let res, chg = (match rest with
  | [] ->
    [], [x (* <1> *), change_at corr EOF msg, rest]
  | (tok, _pos)::rest' when f tok ->
    [tok, corr, rest'], []
  | (_tok, pos)::rest' ->
    [], [x, change_at corr (Coord pos) msg, rest']) in
  if BoundedSet.is_full corr || chg = [] then res
  else List.rev_append res chg
----

So for each possible case (+EOF+, +f+ succeeds or +f+ fails) we prepare both
the result and the altered result and return both whenever possible.

<1> Here we need an example value +x+ of type β in order to change
the outcome of a failure at end of input. Which value exactly is not really a
concern since only its type matters (although the error message could print it
as an example, as OCaml compiler does when complaining about an incomplete
pattern matching.

It is possible to build many simpler and more convenient parsers on top of
+cond+, such as +item+ which expects a specific token in the input, and +range+
which expect anything in the given character range:

.Parsers: the item parser
[source,ml]
----
let item ?(what="item") x =
  cond ("missing "^what) ((=) x) x

let range a b msg =
  cond msg (fun c -> c >= a && c <= b) a
----

.tests
[source,ml]
----
"item canonical success" >:: (
  fun _ctx ->
    assert_same_results Char.print
      ['g', no_corr, List.tl rest]
      (item 'g' no_corr rest)
) ;
"item canonical failure" >:: (
  fun _ctx ->
    assert_same_results Char.print
      []
      (item 'X' no_corr rest)
) ;
"item fails at EOF" >:: (
  fun _ctx ->
    assert_same_results Char.print
      []
      (item 'g' no_corr no_input)
) ;
"item error exploration" >:: (
  fun _ctx ->
    assert_same_results Char.print
      ['X', correction_at (Coord 0) "missing item", List.tl rest]
      (item 'X' corr rest)
) ;
----

== Modifying parsers result

Before going too far we need to introduce functions to alter a parser result (equivalent of map, fold, filter...) and come up with a convenient syntax for those since they are going to be used prevalently.

.Parsers: applying a function to all results of a parser
[source,ml]
----
let map p f corr rest =
  p corr rest |>
  List.map (fun (x, corr, rest) -> f x, corr, rest)
----

The order of parameters is important so that +map p f+ is itself a parser.
An infix operator makes it even more convenient:

.Parsers: infix operator for map
[source,ml]
----
let (>>:) = map
----


== Combinators

The first combinators to consider are the succession of two given parsers, the
alternative of two parsers, and the pipe of one parser result into the input of
another one.

Notice that since we are now merely combining parsers we do not have to care
about error correction any more: only the base parsers need to pretend
succeeding when they fail.

The more general way to build a combinator for the succession of to parsers is
to take the first parser +p1+ and a function +f+ witch, given the output of
+p1+, will return a parser +p2+ to apply to the remaining of the input stream.
Let's call this combinator +bind+ (by analogy with the type of the +bind+
operation in the monad ``design pattern''). The values of +bind p1 f+ are the
values of +p2+, +p1+ intermediary values being only meaningful to build +p2+.

.Parsers: bind
[source,ml]
----
let bind p1 f corr rest =
  (* for each possible result of p1, try to continue parsing with p2 *)
  p1 corr rest |>
  List.fold_left (fun res_list' (x1, corr1, unp1) ->
    let p2 = f x1 in
    match p2 corr1 unp1 with
    | [] -> res_list'
    | res_list2 ->
      List.rev_append res_list2 res_list')
    []
----

With the usual infix operator:

.Parsers: infix operator for bind
[source,ml]
----
let (>>=) = bind
----

Given this +bind+ combinator, the concatenation of two given parsers +p1+ and
+p2+ can be easily written as:

.Parsers: succession of two parsers
[source,ml]
----
let cons p1 p2 =
  p1 >>= (fun x1 -> p2 >>: fun x2 -> x1,x2)
----

Here, we want the final result set to be the product of each
result of +p1+ with all following results of +p2+.

This parser being used to connect successive parsers we'd rather have a shorter
infix alternative for +cons+:

.Parsers: infix operator for cons
[source,ml]
----
let (++) p1 p2 = cons p1 p2
----

Also, we will often discard the result of one parser. For instance when parsing
delimiters the only information is that the parser succeeds (there is a
delimiter) but there is no value to attach to that success. Also when using
the +check+ parser, which purpose is really not its return value. So here are
three variants of +cons+: one that ignores the result of +p1+, one that ignores
the result of +p2+, and one that ignore both (returning +()+):

.Parsers: other convenient infix operators
[source,ml]
----
let (+-) p1 p2 = p1 ++ p2 >>: fst
let (-+) p1 p2 = p1 ++ p2 >>: snd
let (--) p1 p2 = p1 ++ p2 >>: fun _ -> ()
----

Now let's test we can indeed sequence parsers:

.tests
[source,ml]
----
"Can parse a sequence" >:: (
  fun _ctx ->
    let ab = input_of_string "ab" in
    assert_same_results (Tuple2.print Char.print Char.print)
      [('a', 'b'), no_corr, []]
      ((item 'a' ++ item 'b') no_corr ab) ;
    assert_same_results Char.print
      ['a', no_corr, []]
      ((item 'a' +- item 'b') no_corr ab)
) ;
----

The second most useful combinator is the alternative:

.Parsers: alternative
[source,ml]
----
let oneof p1 p2 corr rest =
  let res_list1 = p1 corr rest in
  let res_list2 = p2 corr rest in
  List.rev_append res_list1 res_list2

let (|||) = oneof
----

Notice that results are really sets not list, so the order in which the
alternatives are listed does not matter.  Notice also that this is not an
exclusive alternative: if both +p1+ and +p2+ can parse then both will
contribute a result to the result set. As discussed in the beginning we do
not enforce that if +p1+ succeeds then +p2+ must fail nor the other way
around. If this is wanted though then it is easy enough to write:

.Parsers: exclusive alternative
[source,ml]
----
let either p1 p2 =
  (check "??1" (not p2) -+ p1) ||| (check "??2" (not p1) -+ p2)

let (|/|) = either
----

With sequences and alternatives we can start writing some interesting tests:

.tests
[source,ml]
----
"any: 'a' or 'b' but not 'z'" >:: (
  fun _ctx ->
    let a_or_b = item 'a' ||| item 'b' in
    assert_same_results Char.print
      ['a', no_corr, []]
      (a_or_b no_corr (input_of_string "a")) ;
    assert_same_results Char.print
      ['b', no_corr, []]
      (a_or_b no_corr (input_of_string "b")) ;
    assert_same_results Char.print
      []
      (a_or_b no_corr (input_of_string "z")) ;
    assert_same_results Char.print
      ['a', correction_at (Coord 0) "missing item", [] ;
       'b', correction_at (Coord 0) "missing item", []]
      (a_or_b corr (input_of_string "z"))
) ;
----

Finally, it is often useful to have a first parser output a list of results
which are then feed into another parser. Think for example: splitting character
stream into keywords and then parsing those keywords.

.Parsers: pipe
[source,ml]
----
let pipe p1 p2 corr rest =
  let res_list1 = p1 corr rest in
  List.fold_left (fun res_list (x1, corr1, unp1) ->
    (* x1 is supposed to be a list *)
    let res_list2 = p2 corr1 x1 in
    (* We want the result of p2 with the remained of p1! *)
    List.fold_left (fun res_list (x2, corr2, _unp2) ->
      (* Notice that we do not care about unp2: if the user want to
         make sure that p2 parses all of x then if must make p2 checks this. *)
      (x2, corr2, unp1)::res_list)
      res_list res_list2)
    [] res_list1
----

== Repeating parsers

Binding several parsers already gives us a way to harvest several values from
the input stream but many times what is needed is to repeat the same parser an
unspecified number of times.

Before that, a special case of repetition will prove very useful: having zero
or one occurrence of +p+:

.Parsers: zero or one
[source,ml]
----
let optional ~def p = p ||| return def
let optional_greedy ~def p = (p +- check "??3" (not p)) ||| return def
----

The +repeat+ combinator is a swiss-army knife for all variants of repetitions,
requiring a parser +p+ to succeed from +min+ to +max+ times consecutively, with
an optional additional parser +sep+ for a separator in between +p+ occurrences.
It returns a list of all values returned by the successive +p+.

But allowing +min+ to be +0+ (and making it the default value) we expect to
cut down on the +optional (repeat p)+ that we would have otherwise.

.Parsers: repetition of a parser
[source,ml]
----
let rec repeat ~sep ?(min=0) ?max p corr rest =
  if max = Some 0 then (
    if min = 0 then return [] corr rest
    else fail corr rest
  ) else (
    let pred_ma = match max with None -> None
                               | Some m -> Some (m-1) in
    match min with 0 ->
      (* we may stop here or continue *)
      (optional ~def:[] (repeat ~sep ~min:1 ?max p)) corr rest
                | 1 ->
      (* at least one more, everything else optional *)
      ((p ++ optional ~def:[]
                 (sep -+ (repeat ~sep ~min:1 ?max:pred_ma p))) >>:
        fun (x, xs) -> x::xs) corr rest
                | _ ->
      (* above that, repetition is mandatory *)
      ((p +- sep ++ repeat ~sep ~min:(min-1) ?max:pred_ma p) >>:
        fun (x, xs) -> x::xs) corr rest
  )
----

Notice there are two conditions that terminate the recursion: +max+ reaching
+0+ (no more occurrences permitted) or, when +min > 0+, a failure of +p+.

Notice also that repeat builds a whole list before sending it to the next
stage.  We'd like to get away with this list which, most often than not will be
changed into something else value by value. A lazy list (or a BatEnum) would
likely be preferable here (as in other places).

We'd like to get away with the mandatory +sep+ parameter using a default value
of +return ()+ but that would prevent OCaml compiler to infer that since +sep+
result is consistently discarded any result type would be as good.  Simpler
example of this using the _REPL_:

----
# let f ?sep x = x ;;
val f : ?sep:'a -> 'b -> 'b = <fun>
# let f ?(sep=42) x = x;;
val f : ?sep:int -> 'a -> 'a = <fun>
----

Therefore we merely provide this short do-nothing constant parser to be used
when there is no separator:

.Parsers: none
[source,ml]
----
let none corr = return () corr
----

You may be surprised by this notation, either because you were expecting +let
none corr rest = return () corr rest+ or the shorter +let none = return ()+.
Refer to the appendix about type generalization if that is the case (TODO: link).

We can easily define the greedy version of +repeat+ (that is, a version that
swallows as many +p+ occurrences as present in the input stream) using check:

.(erroneous) greedy repetition
[source,ml]
----
let repeat_greedy ~sep ?min ?max p =
  repeat ~sep ?min ?max p +- check "extraneous" (not (sep -+ p))
----

...which unfortunately fails for +min=0+ because of the separator.  We have to
be more cautious not to allow an input stream starting with +p+ before
returning +[]+:

.Parsers: greedy repetition
[source,ml]
----
let rec repeat_greedy ~sep ?min ?max p =
  match min with
  | None | Some 0 ->
    repeat_greedy ~sep ~min:1 ?max p ||| (check "extraneous" (not p) >>: fun () -> [])
  | min ->
    repeat ~sep ?min ?max p +- (check "extraneous" (not (sep -+ p)) >>: fun _ -> [])
----

.tests
[source,ml]
----
"repetition: canonical successes" >:: (
  fun _ctx ->
    let assert_ok ?(greedy=false) ~sep ?min ?max rest exp =
      assert_same_results (List.print Char.print)
        exp
        ((if greedy then repeat_greedy else repeat) ~sep ?min ?max (item 'a') no_corr rest) in
    let test_with_sep sep sep_len rest =
      let drop n = List.drop (1 + (n-1)*(1+sep_len)) rest in
      assert_ok ~sep rest
        [['a';'a';'a'], no_corr, drop 3 ;
         ['a';'a'],     no_corr, drop 2 ;
         ['a'],         no_corr, drop 1 ;
         [],            no_corr, rest] ;
      (* Same with min=2 *)
      assert_ok ~sep ~min:2 rest
        [['a';'a';'a'], no_corr, drop 3 ;
         ['a';'a'],     no_corr, drop 2] ;
      (* Testing max=2 *)
      assert_ok ~sep ~max:2 rest
        [['a';'a'],     no_corr, drop 2;
         ['a'],         no_corr, drop 1;
         [],            no_corr, rest] ;
      (* Now with min and max *)
      assert_ok ~sep ~min:1 ~max:2 rest
        [['a';'a'],     no_corr, drop 2 ;
         ['a'],         no_corr, drop 1] ;
      (* min = max *)
      assert_ok ~sep ~min:2 ~max:2 rest
        [['a';'a'],     no_corr, drop 2] in
    let aaab = input_of_string "aaab"
    and a_a_a_b = input_of_string "a_a_a_b"
    and _a_a_a_b = input_of_string "_a_a_a_b" in
    test_with_sep none       0 aaab ;
    test_with_sep (item '_') 1 a_a_a_b ;
    assert_ok ~greedy:true ~sep:none aaab
      [['a';'a';'a'], no_corr, List.drop 3 aaab] ;
    assert_ok ~greedy:true ~sep:(item '_') a_a_a_b
      [['a';'a';'a'], no_corr, List.drop 5 a_a_a_b] ;
    (* Do not allow a separator at start *)
    assert_ok ~greedy:true ~sep:(item '_') _a_a_a_b
      [[], no_corr, _a_a_a_b]
) ;
"repetition: simplest failure" >:: (
  fun _ctx ->
    assert_same_results (List.print Char.print)
      []
      (repeat ~sep:none ~min:1 (item 'a') no_corr (input_of_string "zaab")) ;
    assert_same_results (List.print Char.print)
      []
      (repeat_greedy ~sep:none ~min:1 (item 'a') no_corr (input_of_string "zaab"))
) ;
"repetition: missing separator" >:: (
  fun _ctx ->
    assert_same_results (List.print Char.print)
      []
      (repeat ~sep:(item '-') ~min:3 (item 'a') no_corr (input_of_string "a-aab")) ;
    assert_same_results (List.print Char.print)
      []
      (repeat_greedy ~sep:(item '-') ~min:3 (item 'a') no_corr (input_of_string "a-aab"))
) ;
"repetition: below min" >:: (
  fun _ctx ->
    assert_same_results (List.print Char.print)
      []
      (repeat ~sep:none ~min:2 (item 'a') no_corr (input_of_string "baab")) ;
    assert_same_results (List.print Char.print)
      []
      (repeat_greedy ~sep:none ~min:2 (item 'a') no_corr (input_of_string "baab"))
) ;
----

Some variants of +repeat+ can now be defined:

.Parsers: repeat variants
[source,ml]
----
let several ~sep = repeat ~sep ~min:1
let several_greedy ~sep = repeat_greedy ~sep ~min:1
let times ~sep n = repeat ~sep ~min:n ~max:n
----

With all these new combinators, more interesting tests can be devised:

.tests
[source,ml]
----
"Several combinators bound together" >:: (
  fun _ctx ->
    let p = decimal_digit >>= (fun c ->
      let i = Char.code c - Char.code '0' in
      assert_bool "not a digit" (i >= 0 && i <= 9) ;
      (* match a sequence of i zeros *)
      times ~sep:none i (item '0')) in
    let rest1 = input_of_string "105"
    and rest2 = input_of_string "100"
    and rest3 = input_of_string "30005"
    and rest4 = input_of_string "3005" in
    assert_same_results (List.print Char.print)
      [['0'], no_corr, List.drop 2 rest1]
      (p no_corr rest1) ;
    assert_same_results (List.print Char.print)
      [['0'], no_corr, List.drop 2 rest2]
      (p no_corr rest2) ;
    assert_same_results (List.print Char.print)
      [['0';'0';'0'], no_corr, List.drop 4 rest3]
      (p no_corr rest3) ;
    assert_same_results (List.print Char.print)
      []
      (p no_corr rest4)
) ;
----

== Miscellaneous

=== Type generalization

Let's get back to why we haven't defined +none+ simply as +let none = return
()+, using automatic curryfication (TODO: link) to lighten the syntax:

----
# let none = return ();;
             ^^^^^^^^^
Error: The type of this expression, '_a -> '_b -> (unit * '_a * '_b) list,
       contains type variables that cannot be generalized
----

This is actually a limitation of OCaml compiler. Here is what's happening:
normally, in an expression like +let name = expr+, +expr+ will be typed first,
leading in this case where +expr+ is actually +return ()+ to the type +`_a ->
`_b -> (unit * '_a * '_b) list+ (where +'_a+ and +'_b+ are ``weak types''
(refer to the definition of +return+: it's merely a function of 3 parameters
returning a list of the triplet of these 3 parameters). Once +expr+ is typed,
OCaml follow this rule: if +expr+ is a function (as in +function ... ->+), a
constant or an identifier then generalize the weak types into universal types
(the more familiar +'a+, +'b+ etc). If +erpx+ is anything fancier, such as a
partial application as is the case here, then do not generalize.

If instead we had +let name params... = expr+ then, given it's syntactic sugar
for +let name = function ... -> expr+ then the ``weak types'' would have been
generalized.

So we have to make this looks more like a function, by making explicit at least
one parameter (a process famously known under the tickling name
``eta-expansion'').

This feel arbitrary and it is ; aparently this is one of the minor disadvantage
of a typing rules that has plenty of other advantages such as making something
already quite complex much simpler. See the OCaml FAQ (TODO: link) for more
details.

This is unfortunately going to hit us a lot when definin parser combinators
because we'd like to get away with the many meaningless and repetitive
parameters which presence just obfuscate the intent of the code. C'est la vie.

=== BoundedSet

We still have to provide an implementation for our set of fixed maximum size.
The simplest implementation is that of a list with a current size:

.BoundedSet: type
[source,ml]
----
type 'a t =
  { size : int ;
    max_size : int ;
    items : 'a list }
----

With the trivial constructor:

.BoundedSet: constructor
[source,ml]
----
let make max_size =
  { size = 0 ; max_size ; items = [] }
----

And the only two operations we've met so far:

.BoundedSet: operations
[source,ml]
----
let is_full t = t.size >= t.max_size

let add t x =
  { t with size = t.size + 1 ;
           items = x::t.items }
----

=== Printers

If there is something annoying about OCaml it's the lack of default printers
for types. +Batteries+ provides +dump+ but it is oblivious to constructors so
the result is not pretty. So let's write our own.

It would be best to provide formatters instead of mere printers to benefit from
automatic typesetting but unfortunately +Batteries+ support for those is
minimal so it's better to forget about formatters to cut down on typing.

.BoundedSet: printer
[source,ml]
----
open Batteries

let print print_value fmt t =
  List.print print_value fmt t.items
----

.Corrections: printers
[source,ml]
----
open Batteries

let print_position print_coord fmt = function
  | EOF -> String.print fmt "end of input"
  | Coord c -> print_coord fmt c

let print_correction print_coord fmt (pos, msg) =
  Printf.fprintf fmt "%s at %a"
    msg
    (print_position print_coord) pos

let print_corrections print_coord fmt corr =
  BoundedSet.print (print_correction print_coord) fmt corr
----

.Parsers: printers
[source,ml]
----
let print_result print_input print_coord print_output fmt (x, corr, rest) =
  Printf.fprintf fmt "(output=%a,corr=%a,rest=%a)"
    print_output x
    (print_corrections print_coord) corr
    (List.print (fun fmt (tok, _pos) -> print_input fmt tok)) rest
----


== Parsing Perl

Even if we've chosen a different strategy to parse Perl than perl itself,
staying close from perl own parser will guide us through its dense syntax, will
help us be exhaustive and last but not least will provide us with names for the
various syntactic constructs. There is no other somewhat formal description of
the grammar anyway.  Amusingly, the Perl official documentation refers to
``expressions'' and ``statements'' in many places but never defines those.

Therefore, with little edition, here is the _yacc_ grammar from +perly.y+:

Perl modules (and code blocks) consist of a sequence of `statements`:

- stmtseq: stmtseq fullstmt

- fullstmt: LABEL* barestmt
- barestmt: PLUGSTMT | FORMAT ... | SUB ... | PACKAGE ... | USE ...
  | IF (...) ... | UNLESS ... | GIVEN ... | WHEN... | DEFAULT... | WHILE...
  | UNTIL ... | FOR ... | block ... | sideff ';' | ';'

where sideff is anything that can have a side effect:

- sideff: expr | expr IF ... | expr UNLESS ... | expr WHILE ... | expr UNTIL ...
  | expr FOR ... | expr when ...

- expr: expr '&&' expr | expr '||' expr | listexpr
- listexpr: term | listexpr ',' term || listexpr ','

and a term being, intuitively, anything with a value:

- term: termunop | termbinopt | termternaryop | anonymous immediate array, hash or function
  | DO filename | DO block | '\' term | MY ... | LOCAL ... | '(' term ')' | QWLIST | '(' ')'
  | scalar | '*' WORD | '%' WORD | '@' WORD | '$#' WORD | '$#' '{' term '}' | subscript
  | slices | kvslices | '&' WORD ( '(' ( expr )? ')' )? | subname optlistexpr
  '@' '{' term '}' | and friends | GOTO | LAST | DUMP | and friends | REQUIRE term?
  | YADAYADA | listop | ...
- termunop: all kind of unary operators applied to terms
- termbinopt: all kind of binary operators applied to terms
- termternaryop: term '?' term ':' term

We will divide this in four modules, bottom to top:

- PerlImm,
- PerlTerms,
- PerlStmts and
- PerlModules.

=== Immediate values

Now let's try to write parsers for Perl simplest of immediate values, scalars.

==== Numbers

What OCaml type to encode perl integers?

.other tested modules
[source,ml]
----
open PerlImm
----

Notice that a simple base 10 integer number must start with a non 0 (otherwise
it's octal).  We make no exception for the single digit '0' which we will parse
as octal.

.PerlImm: numbers
[source,ml]
----
open Batteries
open Parsers

type integer = Int.t (* FIXME *)

let decimal_digit corr =
  range '0' '9' "digit" corr

let non_zero_decimal_digit corr =
  range '1' '9' "non-zero digit" corr

let num_of_char c =
  let cc = Char.code c in
  if cc >= Char.code '0' && cc <= Char.code '9' then
    cc - Char.code '0'
  else if cc >= Char.code 'a' && cc <= Char.code 'f' then
    cc - Char.code 'a' + 10
  else if cc >= Char.code 'A' && cc <= Char.code 'F' then
    cc - Char.code 'A' + 10
  else invalid_arg "c"

let unsigned_decimal_number corr rest =
  let digits corr = several ~sep:none decimal_digit corr in
  (non_zero_decimal_digit +-
   optional ~def:' ' underscore ++
   optional ~def:[] (several ~sep:underscore digits) >>:
   fun (first, next) ->
   List.fold_left (fun c digits ->
     List.fold_left (fun c digit ->
       c * 10 + num_of_char digit) c digits) 0 ([first]::next)) corr rest

let signed neg p corr =
  (p                                     |||
   item ~what:"sign" '+' -+ p            |||
   (item ~what:"sign" '-' -+ p >>: neg)) corr

let decimal_number corr =
  signed Int.neg unsigned_decimal_number corr
----

We have made +num_of_char+ accept hexadecimal digits in foresight.

Octals, hexadecimal and binary numbers are then build similarly: a mandatory
prefix, and some digits interleaved with underscores. Notice that only the prefix is
mandatory and '0x' for instance is a valid immediate (representing zero of course).

.PerlImm: non decimal integers
[source,ml]
----
let non_decimal_integer base prefix digit corr =
  let digits corr = several ~sep:none digit corr in
  (prefix -+ repeat ~sep:underscore digits >>:
     List.fold_left (fun c digits ->
       List.fold_left (fun c digit ->
         c * base + num_of_char digit) c digits) 0) corr

let octal_digit corr =
  range '0' '7' "octal digit" corr

let octal_number corr =
  (non_decimal_integer 8 (item ~what:"0" '0') octal_digit |>
   signed Int.neg) corr

let hexadecimal_digit corr =
  cond "hexadecimal digit" (fun c ->
    (c >= '0' && c <= '9') ||
    (c >= 'a' && c <= 'f') ||
    (c >= 'A' && c <= 'F')) '1' corr

let non_decimal_integer_prefix x =
  item ~what:"0" '0' --
  cond "integer prefix" (fun c -> Char.lowercase c = x) x

let hexadecimal_number corr =
  let prefix = non_decimal_integer_prefix 'x' in
  (non_decimal_integer 16 prefix hexadecimal_digit |>
   signed Int.neg) corr

let binary_digit corr =
  range '0' '1' "bit" corr

let binary_number corr =
  let prefix = non_decimal_integer_prefix 'b' in
  (non_decimal_integer 2 prefix binary_digit |>
   signed Int.neg) corr
----

Finally, this parser can parse all kind of Perl immediate integers:

.PerlImm: any integer
[source,ml]
----
let integer corr =
  (decimal_number     |||
   octal_number       |||
   hexadecimal_number |||
   binary_number) corr
----

.tests
[source,ml]
----
"integer immediate" >:: (
  fun _ctx ->
    [ "4", 4 ;
      "42", 42 ;
      "12345", 12345 ;
      "4_294_967_296", 4_294_967_296 ;
      "042", 0o42 ;
      "0x42", 0x42 ;
      "0X42", 0x42 ;
      "0xff", 0xff ;
      "0b10", 0b10 ;
      "0x", 0 ;
      "0x4_2", 0x4_2 ;
      "-4", -4 ;
      "+4", 4 ;
      "-042", -0o42 ;
      "+042", 0o42 ;
      "-0x42", -0x42 ;
      "-0b10", -0b10 ] |>
    List.iter (fun (input, output) ->
      assert_same_results Int.print
        [output, no_corr, []]
        ((integer +- eof "char") no_corr (input_of_string input)))
) ;
"not decimal number immediate" >:: (
  fun _ctx ->
    [ "0_" ; "0X_" ; "_123" ; "123_" ; "12__34" ; "_" ; "_0x123" ;
      "-0_" ; "-_42" ] |>
    List.iter (fun input ->
      assert_same_results Int.print
        []
        ((integer +- eof "char") no_corr (input_of_string input)))
) ;
----

The syntax for floating point numbers is more _perly_.  Indeed, in additional
to the usual decimal and scientific notations, Perl allows hexadecimal floating
point, with a power of two as the exponent (and a "p" instead of an"e" to
introduce the exponent, for obvious reason). But this is not allowed in perl
prior to version ...TBD...

Also, notice that you can omit either the integer or the fractional part but
not both.

.PerlImm: floating point
[source,ml]
----
let fractional_part inv_base digit =
  let digits corr = several ~sep:none digit corr in
  several ~sep:underscore digits >>: fun digits ->
    List.fold_left (fun c_scale digits ->
      List.fold_left (fun (c, scale) digit ->
        let n = num_of_char digit |> float_of_int in
        c +. n *. scale, scale *. inv_base) c_scale digits) (0., inv_base) digits |>
    fst

let unsigned_decimal_fractional corr =
  let dot corr = item ~what:"fractional dot" '.' corr in
  ((unsigned_decimal_number +- dot ++ fractional_part 0.1 decimal_digit) |||
   (return 0 +- dot ++ fractional_part 0.1 decimal_digit)                |||
   (unsigned_decimal_number +- dot ++ return 0.) >>:
       fun (n, p) -> float_of_int n +. p
  ) corr

let decimal_fractional corr =
  signed Float.neg unsigned_decimal_fractional corr

let decimal_scientific corr =
  ((decimal_fractional |||
    (decimal_number >>: float_of_int)) +-
   cond "exponent delimiter" (fun c -> c = 'e' || c = 'E') 'e' ++
   decimal_number >>: fun (m, e) ->
     m *. Float.pow 10. (float_of_int e) (* FIXME *)
   ) corr

let floating_point corr =
  (decimal_fractional |||
   decimal_scientific) corr
----

.tests
[source,ml]
----
"floating point notation" >:: (
  fun _ctx ->
    [ "3.14", 3.14 ;
      "-3.14", -3.14 ;
      "314e2", 31400. ;
      "314e-2", 3.14 ;
      ".1", 0.1 ;
      "1.", 1.0 ] |>
    List.iter (fun (input, output) ->
      assert_same_results Float.print
        [output, no_corr, []]
        ((floating_point +- eof "char") no_corr (input_of_string input)))
) ;
----

And finally the function that reads any immediate number:

.PerlImm: number
[source,ml]
----
type number = Int of integer
            | Float of float
let number corr =
  ((integer        >>: fun x -> Int x) |||
   (floating_point >>: fun x -> Float x)) corr
----

TODO: explain why sometime it's ok to get away with the other arguments and
sometime we get the "some type variable can;t be generalized" error.

==== Strings

Although basic string notation are similar to what is implemented in many other
languages, Perl strings are harder to parse because they require a context for
the automatic quoting of lists, anything "not too complicated" inside curly
braces or first operands of +=>+. In fact, any bare words that is neither a
keyword not a function call is actually a string. To parse a bare word as a
string you therefore need to know all possible function names, which is not
going to happen before you are able to actually run that code. Consequently
we will have a special type of token for bare words, remembering that they can
be either function calls or strings.

Other peculiarity: the seldom used v-string notation, which interpretation
depends on its location and length (and, in theory, on perl versions).

Also, despite one of our goal being to interpret strings as much as possible
including in the presence of +eval+, we will make no such attempt in the first
stage of parsing and will wait until much later to run the interpolation
process (Remember: a single run of interpolation!)

Let's start with the basics: the non interpolated string (aka. single quoted
string in which no replacement take place).  This is basically any characters
between single quotes, including new lines. The backslash can escape single
quote and backslash, but any other backslash represents merely itself (ie.
``\a'' encodes nothing more than a ``\'' followed by ``a'').

.PerlImm: non-interpolated strings
[source,ml]
----
type string =
    NoInterpString of String.t
  (* ...other perl string types... *)

let backslash corr = item ~what:"backslash" '\\' corr
let single_quote corr = item ~what:"single quote" '\'' corr

let single_quoted_character corr =
  ((backslash -+ backslash)    |||
   (backslash -+ single_quote) |||
   (backslash -+ cond "escaped character" (fun c->
     if PerlPersona.allow_any_escaped_char_in_single_quoted_string
     then c <> '\\' && c <> '\''
     else false) 'n') |||
   (cond "character" (fun c ->
     c <> '\\' && c <> '\'' &&
     (if PerlPersona.allow_newlines_in_quoted_strings then true
      else c <> '\n' (* actual newline not "\n" sequence *))) 'x')) corr

let single_quoted_string corr =
  (single_quote -+ repeat ~sep:none single_quoted_character +- single_quote >>:
   fun s -> NoInterpString (String.of_list s)) corr
----

With that module that we will use to personalize our parser behavior to mimic various Perl versions:

.PerlPersona: some parameters to customize parser behavior
[source,ml]
----
(* Temporary. *)
let allow_any_escaped_char_in_single_quoted_string = true
let allow_newlines_in_quoted_strings = true
----

TODO: replace this with a module that's set to a given implementation of the
PERL_PERSONALITY signature.

Interpolated strings, aka double quoted strings, differs in how the backslash is handled.
There, many backslash sequences are recognized, and any unknown backslash sequence is an error.

.other perl string types
[source,ml]
----
| InterpString of String.t
----

.PerlImm: interpolated strings
[source,ml]
----
let double_quote corr = item ~what:"double quote" '"' corr

let hexadecimal_digit_value corr =
  (hexadecimal_digit >>: num_of_char) corr

let double_quoted_character corr =
  (backslash -+ (
      backslash    |||
      single_quote |||
      double_quote |||
      (cond_map "escaped character" (function
        | 'f' -> Some '\014'
        | 'n' -> Some '\n'
        | 'r' -> Some '\r'
        | 't' -> Some '\t'
        | _ -> None) 'a') |||
      (item ~what:"hexadecimal prefix" 'x' -+
       hexadecimal_digit_value ++ hexadecimal_digit_value >>:
       fun (d1, d2) -> Char.chr (d1*16 + d2)) (* TODO: \cX for control characters *)
   ) |||
   cond "character" (fun c ->
     c <> '"' && c <> '\\' &&
     (if PerlPersona.allow_newlines_in_quoted_strings then true
      else c <> '\n' (* actual newline not "\n" sequence *))) 'x') corr

let double_quoted_string corr =
  (double_quote -+ repeat ~sep:none double_quoted_character +- double_quote >>:
   fun s -> InterpString (String.of_list s)) corr
----

Notice the introduction of +cond_map+ which is a +cond+ that returns an
optional value instead of a mere boolean:

.Parsers: cond_map
[source,ml]
----
let cond_map msg f x corr rest =
  let res, chg = match rest with
    | [] ->
      [], [x, change_at corr EOF msg, rest]
    | (tok, pos)::rest' ->
      (match f tok with
       | Some v -> [v, corr, rest'], []
       | None   -> [], [x, change_at corr (Coord pos) msg, rest']) in
  if BoundedSet.is_full corr || chg = [] then res
  else List.rev_append res chg
----

from which we can write a simpler +cond+ parser:

.Parsers: the cond parser, revisited
[source,ml]
----
let cond msg f =
  cond_map msg (fun c -> if f c then Some c else None)
----

TODO: in portia, an definition starting with same name a one that already
exist, followed by a coma and something should replace it in the output instead
of been appended to it.

And finally the back-quoted string, which is for now exactly as the double
quoted string:

.other perl string types
[source,ml]
----
| ExecedString of String.t
----

.PerlImm: backquoted strings
[source,ml]
----
let back_quote corr = item ~what:"back-quote" '`' corr

let back_quoted_string corr =
  (back_quote -+ repeat ~sep:none double_quoted_character +- back_quote >>:
   fun s -> ExecedString (String.of_list s)) corr
----


Version strings are sequence of integers separated by dot and usually prefixed
by ``v'' (mandatory when there are at least 3 numbers -- when there are only
two of course this is a fractional number).

.PerlImm: v-strings
[source,ml]
----
let vstring corr =
  let dot = item ~what:"vstring separator" '.' in
  (item ~what:"vstring prefix" 'v' -+ several ~sep:dot decimal_number |||
   repeat ~sep:dot ~min:3 decimal_number >>: fun nums ->
     let l = List.length nums in
     let s = String.create l in
     List.iteri (fun i n ->
       s.[i] <- Char.chr n (* TODO: non ASCII characters *)) nums ;
     NoInterpString s
   ) corr
----

Which we'd better write tests for:

.PerlImm: printers
[source,ml]
----
let print_string fmt = function
  | NoInterpString s -> Printf.fprintf fmt "'%s'" s
  | InterpString s   -> Printf.fprintf fmt "\"%s\"" s
  | ExecedString s   -> Printf.fprintf fmt "`%s`" s
  (* ...other printers for immediate strings... *)
----

.tests
[source,ml]
----
"string immediate" >:: (
  fun _ctx ->
    assert_same_results print_string
      [NoInterpString "glop", no_corr, []]
      (single_quoted_string no_corr (input_of_string "'glop'"))
) ;
"vstring immediate" >:: (
  fun _ctx ->
    assert_same_results print_string
      [NoInterpString "A", no_corr, []]
      ((vstring +- eof "number") no_corr (input_of_string "v65")) ;
    assert_same_results print_string
      [NoInterpString "AB", no_corr, []]
      ((vstring +- eof "number") no_corr (input_of_string "v65.66")) ;
    assert_same_results print_string
      [NoInterpString "ABC", no_corr, []]
      ((vstring +- eof "number") no_corr (input_of_string "v65.66.67")) ;
    assert_same_results print_string
      [NoInterpString "ABC", no_corr, []]
      ((vstring +- eof "number") no_corr (input_of_string "65.66.67")) ;
) ;
----

Finally some special literals are predefined strings:

.other perl string types
[source,ml]
----
| FileString
| LineString
| PackageString
| SubString
| DataString of String.t
----

.other printers for immediate strings
[source,ml]
----
| FileString    -> Printf.fprintf fmt "__FILE__"
| LineString    -> Printf.fprintf fmt "__LINE__"
| PackageString -> Printf.fprintf fmt "__PACKAGE__"
| SubString     -> Printf.fprintf fmt "__SUB__"
| DataString _s -> Printf.fprintf fmt "__DATA__"
----

.PerlImm: special predefined string literals
[source,ml]
----
let predefined_string corr =
  ((string "__FILE__"    >>: replace FileString)    |||
   (string "__LINE__"    >>: replace LineString)    |||
   (string "__PACKAGE__" >>: replace PackageString) |||
   (string "__SUB__"     >>: replace SubString)     |||
   (string "__DATA__" -+ repeat ~sep:none anything +- eof "DATA"
                         >>: fun l ->
                               DataString (String.of_list l))) corr
----

with a few new combinators so trivial we couldn't have envisioned they'd turn useful:

.Parsers: trivial parsers and utilities
[source,ml]
----
let string s =
  let rec loop i =
    if i >= String.length s then return ()
    else (
      (item ~what:s s.[i]) -- (loop (i+1))
    ) in
  loop 0

let replace x _ = x

let anything corr = function
  | [] -> []
  | (tok,_pos)::rest' -> [tok, corr, rest']
----

Notice that +anything+ cannot really fail.

Finally, here is our string parser:

.PerlImm: string parser
[source,ml]
----
let string corr =
  (single_quoted_string |||
   double_quoted_string |||
   vstring              |||
   predefined_string) corr
----

==== Any scalar values

Here is the final parser for any scalar value, including ``undef'' which is the
default value for uninitialized scalars and which can also be mentioned
literally:

.PerlImm: final scalar parser
[source,ml]
----
type scalar = Undef
            | String of string
            | Number of number
let scalar corr =
  ((string >>: fun s -> String s) |||
   (number >>: fun n -> Number n) |||
   (Parsers.string "undef"
           >>: replace Undef))  corr
----

=== Terms

==== Terms and whitespaces

White spaces are easy, we just have to remember that new lines and comments also
act as white spaces:

.PerlTerm: whitespaces
[source,ml]
----
open Parsers

let whitespace corr =
  let ws corr =
    (cond "space" (fun c ->
      c = ' ' || c = '\t' || c = '\n') ' ') corr in
  let eol corr =
    (item ~what:"end of line" '\n') corr  in
  let comment corr =
    (item ~what:"comment" '#' +-
     repeat_greedy ~sep:none (not eol) +-
     eol) corr in
  (repeat_greedy ~sep:none (ws ||| comment)) corr

let opt_whitespace corr =
  optional_greedy ~def:[] whitespace corr
----

Notice we read greedily the whitespaces because we want to avoid a +whitespace
-- whitespace+ ambiguity and that we also have an +optional_greedy+ for the same
reason.

==== Operations

There are, mostly, two classes of operators: those which coerce their arguments
into strings and those which coerce their arguments into numbers (note that the
`boolean' operators belong to this category since booleans are just numbers in
Perl).  But there are exceptions of course: the _DOR_ operator (defined-or,
``//'') and the assignment operator do not force a context on their arguments,
for instance, and works not only for scalars. The ternary operator coerce only
its predicate but neither its consequent nor its alternative.

Notice that, from the grammar standpoint, the assignment is a binary operator.

Notice also that +cmp+ is a string operator, so that +9 cmp 10+ returns
counter-intuitively +1+ since the character '9' is ``greater'' than the
character '1'.

Here we define only one type for all operators, which context (string or
number) is given by a function, instead of defining two levels of constructors,
in order to shorten the code - and the encoding of values.

.PerlTerm: binary operators
[source,ml]
----
type binop = EqOpString | GtOpString | LtOpString
           | NeOpString | CmpOpString | DotOpString
           | EqOpNumber | GtOpNumber | LtOpNumber
           | NeOpNumber | GEOpNumber | LEOpNumber
           | AddOp | SubOp | MulOp | DivOp
           | ExpOp | ModOp | AssignOp
           | LShiftOp | RShiftOp
           | BitAndOp | BitOrOp | RangeOp
           | AndOp | OrOp | DefOrOp (* // *)
           | MatchOp (* =~ *)

let binop corr =
  ((string "eq"  >>: replace EqOpString)  |||
   (string "gt"  >>: replace GtOpString)  |||
   (string "lt"  >>: replace LtOpString)  |||
   (string "ne"  >>: replace NeOpString)  |||
   (string "cmp" >>: replace CmpOpString) |||
   (string "."   >>: replace DotOpString) |||
   (string "=="  >>: replace EqOpNumber)  |||
   (string ">"   >>: replace GtOpNumber)  |||
   (string "<"   >>: replace LtOpNumber)  |||
   (string "!="  >>: replace NeOpNumber)  |||
   (string ">="  >>: replace GEOpNumber)  |||
   (string "<="  >>: replace LEOpNumber)  |||
   (string "+"   >>: replace AddOp)       |||
   (string "-"   >>: replace SubOp)       |||
   (string "*"   >>: replace MulOp)       |||
   (string "/"   >>: replace DivOp)       |||
   (string "**"  >>: replace ExpOp)       |||
   (string "%"   >>: replace ModOp)       |||
   (string "="   >>: replace AssignOp)    |||
   (string "<<"  >>: replace LShiftOp)    |||
   (string ">>"  >>: replace RShiftOp)    |||
   (string "&"   >>: replace BitAndOp)    |||
   (string "|"   >>: replace BitOrOp)     |||
   (string ".."  >>: replace RangeOp)     |||
   (string "&&"  >>: replace AndOp)       |||
   (string "||"  >>: replace OrOp)        |||
   (string "//"  >>: replace DefOrOp)     |||
   (string "=~"  >>: replace MatchOp)) corr
----

Unary operators are similar:

.PerlTerm: unary operators
[source,ml]
----
type unop = MinusOp | PlusOp | NotOp | FlipOp
          | PostIncOp | PostDecOp | PreIncOp | PreDecOp

let unop_prefix corr =
  ((item '-' >>: replace MinusOp)     |||
   (item '+' >>: replace PlusOp)      |||
   (item '!' >>: replace NotOp)       |||
   (item '~' >>: replace FlipOp)      |||
   (string "++" >>: replace PreIncOp) |||
   (string "--" >>: replace PreDecOp)) corr

let unop_postfix corr =
  ((string "++" >>: replace PostIncOp) |||
   (string "--" >>: replace PostDecOp)) corr
----

And finally, the (only) ternary operator:

Eventually, to define a term we will have to define recursively the many
possible shapes a term can have.  Unfortunately we an not follow too closely
perl own parser because of it's heavy reliance on left recursion, which an
combinatory parser can't do. Instead, we will have to _force_progress_ by
defining a chain of terms and subterms in order of precedence.

The principle of such a chain is to replace a left recursing definition such as:

[source,ml]
----
let term corr = (term +- any_binary_op ++ term) corr
----

with:

[source,ml]
----
let term1 corr = ((term2 +- low_precedence_op ++ term2) ||| term2) corr
let term2 corr = ((term3 +- higher_precedence_op ++ term3) ||| term3) corr
(* etc... *)
----

allowing recursion only after some input have been consumed:

[source,ml]
----
let rec this_is_ok corr =
  (item '{' -+ this_is_ok ++ item '}') corr
let rec this_is_infinite_recursion corr =
  (this_is_infinite_recursion ++ anything_else) corr
let rec this_is_still_infinite_recursion corr =
  (check "a check does not consume" some_check ++
   this_is_still_infinite_recursion) corr
----

Now this chain will always parse left side first. If +1 + 2 * 3+ will properly
be parsed as +1 + (2 * 3)+ (because the parse would fail if +term1+ consumed
only +1 + 2+), the simple +3 - 2 - 1+ would be erroneously parsed as +3 - (2 -
1)+ instead of +(3 - 2) - 1+. To help with left associative operators, we need
to group operators of same precedence and associativity and use a +repeat+
parser, which associativity we are free to choose.

Here is a +binary_ops_reducer+ parser that takes a parser for binary operators
of same associativity and precedence (here called +op+), and a parser for terms
(called +term+), and returns either the left or right associativity parser. It
is expected that the +term+ parser has higher precedence. It bear some
resemblance with +repeat+ but does not discard the output of the separator
(here: the operation) and build as a last stage the final result out of the
list of partial results, with the expected associativity.  This situation
occurs often enough in practice that it's worth having a generic solution in
the parser combinator library. It is made generic enough by the use of another
parameter, the +reduce+ function, that combines two terms and an operator
results into a value of the same type as returned by term. Notice that this may
force the user of this +binary_ops_reducer+ function to `lift` the sub-term
parser in order to return a singleton term instead (if the sub-terms and terms
do not share a common type).

.Parsers: binary operations with selected associativity
[source,ml]
----
let binary_ops_reducer ?(right_associative=false) ~op ~term ~sep ~reduce corr =
  (term +- sep ++ repeat ~sep (op +- sep ++ term) >>:
   fun (fst, lst) -> (* lst is a list of (op result * term result) *)
     let rec loop_lst last_term = function
       | [] -> last_term
       | (op, next_term)::rest ->
         if right_associative then
           reduce last_term op (loop_lst next_term rest)
         else
           loop_lst (reduce last_term op next_term) rest
         in
     loop_lst fst lst) corr
----

Let's test it:

.tests
[source,ml]
----
"binary_ops_reducer" >:: (
  fun _ctx ->
    let term corr = (decimal_digit >>: fun c -> Term c) corr in
    let op corr = item '+' corr in
    let reduce t1 _op t2 = Op (t1, t2) in
    [ "1+2",
        Op (Term '1', Term '2'),
        Op (Term '1', Term '2') ;
      "1+2+3",
        Op (Op (Term '1', Term '2'), Term '3'),
        Op (Term '1', Op (Term '2', Term '3')) ;
      "1+2+3+4",
        Op (Op (Op (Term '1', Term '2'), Term '3'), Term '4'),
        Op (Term '1', Op (Term '2', Op (Term '3', Term '4'))) ] |>
    List.iter (fun (input_str, e1, e2) ->
      (* e1 is the expected result for left associative parsing and
         e2 for right associative parsing. *)
      let input = input_of_string input_str in
      assert_same_results ~msg:"left assoc." binary_ops_reducer_test_result_print
        [e1, no_corr, []]
        ((binary_ops_reducer ~op ~term ~sep:none ~reduce ~right_associative:false
          +- eof "term") no_corr input) ;
      assert_same_results ~msg:"right assoc." binary_ops_reducer_test_result_print
        [e2, no_corr, []]
        ((binary_ops_reducer ~op ~term ~sep:none ~reduce ~right_associative:true
          +- eof "term") no_corr input))
) ;
----

with type +binary_ops_reducer_test_result+ defined globally, as required by OCaml:

.other global functions or types for testing
[source,ml]
----
type binary_ops_reducer_test_result = Term of Char.t
                                    | Op of (binary_ops_reducer_test_result *
                                             binary_ops_reducer_test_result)

let rec binary_ops_reducer_test_result_print fmt = function
  | Term c ->
     Printf.fprintf fmt "%c" c
  | Op (r1, r2) ->
     Printf.fprintf fmt "(%a+%a)"
       binary_ops_reducer_test_result_print r1
       binary_ops_reducer_test_result_print r2
----

Let's also test the handling of precedence with a small calculator:

.tests
[source,ml]
----
"precedence and associativity" >:: (
  fun _ctx ->
    let value corr = (decimal_digit >>: num_of_char) corr in
    let reduce t1 op t2 = match op with
      | '+' -> t1+t2 | '-' -> t1-t2
      | '*' -> t1*t2 | '/' -> t1/t2
      | '^' -> int_of_float((float_of_int t1)**(float_of_int t2))
      | _ -> assert false in
    let rec left_assoc_low_prec corr =
      binary_ops_reducer ~op:(item '+' ||| item '-')
                         ~term:left_assoc_high_prec
                         ~sep:none ~reduce corr
    and left_assoc_high_prec corr =
      binary_ops_reducer ~op:(item '*' ||| item '/')
                         ~term:right_assoc_higher_prec
                         ~sep:none ~reduce corr
    and right_assoc_higher_prec corr =
      binary_ops_reducer ~op:(item '^')
                         ~right_associative:true
                         ~term:left_assoc_highest_prec
                         ~sep:none ~reduce corr
    and left_assoc_highest_prec corr =
      (value |||
       item '(' -+ left_assoc_low_prec +- item ')') corr in
    [ "0",            0 ;
      "1+2",          3 ;
      "1+2+3",        6 ;
      "1+2+3+4",     10 ;
      "5-1",          4 ;
      "5-4-1",        0 ;
      "(5-4)-1",      0 ;
      "5-(4-1)",      2 ;
      "4^3^2",   262144 ;
      "4^(3^2)", 262144 ;
      "(4^3)^2",   4096 ;
      "3*2+1",        7 ;
      "1+3*2",        7 ;
      "(1+3)*2",      8 ;
      "8/2/2",        2 ] |>
    List.iter (fun (input_str, exp) ->
      let input = input_of_string input_str in
      assert_same_results Int.print
        [exp, no_corr, []]
        ((left_assoc_low_prec +- eof "term") no_corr input))
) ;
----

Now that we are confident we can parse operators with any precedence and
associativity despite using parser combinators, let's have a look at perl
operators.  Here is a list of all operators in precedence order, along with the
name we will give to the parser:

.Operators by precedence
[cols="m,^,m",frame="topbot",options="header"]
|===========================================================
| operator    | associativity | parser
| ->          | left          | deref_op
| ++, --      | non           | pre_post_inc_dec
| **          | right         | pow_op
| ! ~ \ + -   | right         | unary_op
| =~ !~       | left          | regexp_op
| * / % x     | left          | mul_op
| + - .       | left          | plus_op
| << >>       | left          | shift_op
| < > <= >= lt gt le ge | non           | cmp_op
| == != <=> eq ne cmp ~~ | non          | eq_op
| &           | left          | bitand_op
| \| ^        | left          | bitor_op
| &&          | left          | logand_op
| \|\| //     | left          | logor_op
| .. ...      | non           | range_op
|  ?:         | right         | cond_op
| = += -= *= etc. | right     | assign_op
| goto last next redo dump | right       | loop_op
| , =>        | left          | coma_op
| list operators (rightwards) | right          | list_op
| not         | right         | not_op
| and         | left          | and_op
| or xor      | left          | or_op
|===========================================================

Let's start with the unary, binary and ternary operations:

.PerlTerm: term type and parser
[source]
----
type t = UnaryOp of unop * t
       | BinaryOp of t * binop * t
       | TernaryOp of t * t * t
       (* ...other constructors for terms... *)

let rec pre_post_inc_dec corr =
  ((unop_prefix ++ pow_op  >>: fun (o,t) -> UnaryOp (o, t)) |||
   (pow_op ++ unop_postfix >>: fun (t,o) -> UnaryOp (o, t)) |||
   pow_op) corr

(*and pow_op corr =*)


(* FIXME: left recursive!!
Change into -> repeat ~sep:binop sub_term
where sub_term is not allowed to start with a term.

Ternary operator?
term = repeat ~sep:(binop ||| '?' ||| ':') sub_term
And parse again to reassemble the ternary operators.
Alternative: term_with_ternaryop = term ++ optional ('?' term ':' term)
because "1 + 2 ? 3 : 4" parses as 3 not 4 (all ops but assignments are more prio than ternary op).

Postfix inc/dec?
if we also allow "term = sub_term ++ postfix_op" then we can no longer
post-inc a term ; in other words, we cannot write: $x++ ++ which is illegal anyway (even if perl parses it) because ++/-- are non-associative.

Easier maybe to build the term by percedence order: start with "subterm1 = several ~sep:'**' subterm",
then "subterm2 = several ~sep:'=~' subterm1" and so on?

This has no more left recursion, and should accept the same input. Also makes useless to reorder according to precedence.

Of course subterm is allowed to reuse term, but not as a leftmost parser.

*)
let rec term corr =
  ((term ++ binop ++ term >>: fun ((t1,o),t2) -> BinaryOp (t1, o, t2)) |||
   (unop_prefix ++ term  >>: fun (o,t) -> UnaryOp (o, t))              |||
   (term ++ unop_postfix >>: fun (t,o) -> UnaryOp (o, t))              |||
   (term +- item ~what:"ternary operator (?)" '?' ++
    term +- item ~what:"ternary operator (:)" ':' ++
    term >>: fun ((p,c),a) -> TernaryOp (p, c, a))
   (* ...other syntaxes for terms... *)) corr
----

==== Scalar immediate

Next on our list is the scalar. Thanks to PerlImm we do not have much to do:

.other constructors for terms
[source,ml]
----
| Scalar of PerlImm.scalar
----

.other syntaxes for terms
[source,ml]
----
||| (PerlImm.scalar >>: fun s -> Scalar s)
----

==== Anonymous Array and Hash

Arrays or hashes are mostly made of lists, which are made of expressions
(+expr+ in perl parser), which are either lists of expressions or expressions
combined with logical operators. Which is annoyingly left-recursive.

.PerlTerm: expressions
[source]
----
let rec expr corr =
  ((expr ...)) corr
----

==== Anonymous Function



==== Variables and array lengths

==== Subscripts and slices

==== Reference

==== Dereferences

==== Lists and parentheses

==== Function calls

===== old style

===== new style

==== DO filename or block

==== Goto, last, and friends

==== Require

==== My, Local...

==== Yada yada and even more obscure terms

==== Words: Identifiers, Keywords, Barewords...

Half-strings half-keywords, ``barewords'' are the first monstrous beasts of
Perl demonology.  Barewords are all word-like things that are not keywords.  In
many contexts, barewords will be mere unquoted non-interpolated strings. Even
an integer can be a bareword (between curly braces: in ``{42}'', +42+ is indeed
a bareword that will be equivalent to the string +"42"+ not an integer - also
before the auto-quoting operator +=>+ of course). Barewords are strings each
time they are not function calls, which sometime can be determined only at
runtime.

Given barewords are defined to be any name that's not a keyword nor a function
call, we must first define names, then keywords. We will leave function
calls for later.

First of all, like in many other programming language, names begin with a
letter or an underscore and may optionally include any combination of letters,
numbers, and underscores:

.PerlTerm: names
[source,ml]
----
open Batteries
open Parsers

let name corr =
  let first_char corr =
    (letter ||| underscore) corr in
  let char corr =
    (letter ||| PerlImm.decimal_digit ||| underscore) corr in
  (first_char ++ repeat_greedy ~sep:none char >>: fun (h,tl) ->
    String.of_list (h::tl)) corr

let fully_qualified_name corr =
  (several ~sep:(string "::") name) corr
----

with the general enough purpose functions that we can add to the base library of
parsers:

.Parsers: basic character recognition parsers
[source,ml]
----
let lowercase corr = range 'a' 'z' "lowercase" corr
let uppercase corr = range 'A' 'Z' "uppercase" corr
let letter corr = (lowercase ||| uppercase) corr
let underscore corr = item '_' corr
----

.tests
[source,ml]
----
"valid names" >:: (
  fun _ctx ->
    [ "glop" ; "Glop" ; "_gl0p_" ] |>
    List.iter (fun s ->
      assert_same_results String.print
        [s, no_corr, []]
        (PerlTerm.name no_corr (input_of_string s)))
) ;
"invalid names" >:: (
  fun _ctx ->
    [ "0glop" ; " v" ; "" ] |>
    List.iter (fun s ->
      assert_same_results String.print
        []
        (PerlTerm.name no_corr (input_of_string s)))
) ;
----

Let's now call ``identifier'' any name with a prefix:

.PerlTerm: identifiers
[source,ml]
----
type identifier_sigil = NoSigil
                      | ScalarSigil | ArraySigil
                      | HashSigil | FunctionSigil
type identifier = identifier_sigil * string

let identifier_sigil corr =
  ((item ~what:"scalar sigil" '$'   >>: replace ScalarSigil) |||
   (item ~what:"array sigil" '@'    >>: replace ArraySigil)  |||
   (item ~what:"hash sigil" '%'     >>: replace HashSigil)   |||
   (item ~what:"function sigil" '&' >>: replace FunctionSigil)) corr

let identifier corr =
  (optional ~def:NoSigil identifier_sigil ++ name) corr
----

Now let's try to recognize keywords:

.PerlTerm: keywords
[source,ml]
----
let keyword corr =
  (string "if" ||| string "unless"   |||
   string "while" ||| string "until" |||
   string "else") corr
----

So that finally we can tell a bareword from a keyword:

.PerlTerm: barewords
[source]
----
let bareword corr =
  (check "not a keyword" (not keyword) -+ name) corr
----

.other term types
[source]
----
| Bareword of String.t
----


==== Lists

Beside immediate scalar values and barewords, a term can also be a list,
which is recursively made of other terms.

List parsing is, as many Perl things, inconsequential. If the documentation
insists that ``parentheses do not make lists, comas do'', the empty list in
nonetheless represented as +()+.  But it is true that +(1,2,(3,4))+ is truly
just +(1,2,3,4)+ (the second pair of parentheses does not introduce a sublist),
as +(1,(),2)+ is just +(1,2)+, and that unless ordering of evaluation commands
otherwise +(1,2,3)+ is equivalent as +1,2,3+.

Notice that any coma can be an auto-quoting variant +=>+ instead, which (tries
to) make the left item a string, and that the final coma (or auto-quoting
separator) is optional.

Given the recursive nature of lists we will define the +list+ parser and the
+list_item+ parser as mutually recursive, and will let the +term+ and
+whitespace+ parsers definition for later:

.PerlTerm: list item
[source]
----
let left_parenth corr =
  item ~what:"left parenthesis" '(' corr
let right_parenth corr =
  item ~what:"right parenthesis" ')' corr
let coma corr =
  item ~what:"coma" ',' corr
let autoquoting_coma corr =
  string "=>" corr

let rec list_item corr =
  (((term >>: List.singleton) |||
    (left_parenth -+ list +- right_parenth))
   +- opt_whitespace ++
   ((coma >>: replace false) |||
    (autoquoting_coma >>: replace true)) +-
   opt_whitespace >>:
   function [Bareword w], true -> [Scalar (String (NoInterpString w))]
          | x, _ -> x) corr
----

Notice that the only case where the automatic quotation serves any purpose is when it's present after a bareword.

Also, this +list_item+ parser always return a list (either with many
terms as returned by the +list+ parser or with a single element if there
was actually no sublist). All these sublists will have to be flattened in the
+list+ parser. That's definitively not the most efficient way to write this
parser but it makes it more readable.

Notice also that to avoid infinite left recursion we must make sure of the
presence of an opening parenthesis before recursing into +list+. The list
parser itself will look for the optional presence of the parenthesis, just so
that we can call it to parse a top-level lists.

The +optional_greedy+ above is to avoid terminating a parser on an optional
parser, which results in two possible result systematically, which the caller
will not necessarily reduce if the next parser starts with the same optional
parser. Indeed,

[source,ml]
----
optional p ++ optional p
----

would yield 2 equivalent results.

Given this +list_item+, now we can add the +list+ parser that will return parsed (into an OCaml list of
terms) with:

.PerlTerm: lists
[source]
----
and list corr =
  (((left_parenth -+ repeat ~sep:none list_item +- right_parenth) |||
    (repeat ~sep:none list_item)                                  |||
    empty_list) >>: List.flatten) corr
and empty_list corr =
  ((left_parenth -- right_parenth) >>: replace []) corr
----

That we cannot test until we define +term+ and +whitespace+.

==== Anonymous arrays

Array references are really nothing more than a list within brackets:

.PerlTerm: anonymous arrays
[source]
----
let left_bracket corr =
  item ~what:"left bracket" '[' corr
let right_bracket corr =
  item ~what:"right bracket" ']' corr

let anonymous_array corr =
  (left_bracket -- opt_whitespace -+
   list +-
   opt_whitespace +- right_bracket) corr
----

==== Anonymous Hashes

And the same goes for anonymous hashes, with curly brackets:

.PerlTerm: anonymous hashes
[source]
----
let left_curly_bracket corr =
  item ~what:"left curly bracket" '{' corr
let right_curly_bracket corr =
  item ~what:"right curly bracket" '}' corr

let anonymous_hash corr =
  (left_curly_bracket -- opt_whitespace -+
   list +-
   opt_whitespace +- right_curly_bracket) corr
----

=== Statements

The simplest statement is known to be a single term (ended with a
semicolon), supposedly evaluated for its side-effects:

.PerlStmt: what is this?
[source]
----
open Parsers
let term = PerlTerm.term

let statement corr =
  (term
   (* ...other statements... *)) corr
----

==== Ellipsis

The easiest of the statements is the ellipsis, a placeholder for unimplemented code.
Notice that ellipsis can also be a binary operator in some occasions.

.PerlStmt: ellipsis
[source,ml]
----
open Parsers (* again *)
let ellipsis corr =
  (if PerlPersona.ellipsis_is_a_valid_statement
   then string "..."
   else fail) corr
----

.PerlPersona: more options
[source,ml]
----
let ellipsis_is_a_valid_statement = true;
----

=== Modules

