// vim:filetype=asciidoc expandtab spell spelllang=en ts=2 sw=2
= Homegrown Parser Combinators with error detection
rixed@happyleptic.org
v0.1, 2015-10-27
:toc:
:numbered:
:icons:
:lang: en
:encoding: utf-8

== What is this?

This document describe the implementation of a library to perform text
parsing according to a technique called
https://en.wikipedia.org/wiki/Parser_combinator[parser combinators] because the
parser for a given grammar is build combining simpler parsers. This technique
is fashionable although old and slow because it is simple and permissive.

This is also an example of literate programming; in case the notations used in
this document are unclear you can read about them in
http://rixed.github.io/portia/notations.html[this document].

== Requirements

=== Parsing perl as deep as possible without executing it

This is our ultimate objective, that drives all of the following requirements.

=== Parsing recursively

Perl has +eval+ on strings. Therefore we do not want to stop parsing a soon as
we reach a string literal if it's (or could be) passed to the +eval+ function.

=== Parsing with gaps

For the same reason, we want to be able to parse as much as possible of a code
string even if we are missing some part of it.

=== Best effort

It will not always be possible to know for sure the type of all symbols. In
that case we want to present all possible alternatives as the result, rather
than stopping the parse or selecting the most probable one.

=== Error detection?

The code that will be sent to this parser will already be valid most of the time..
Therefore, the error reporting need not detect typos or other user error.
Essentially, we need error reports merely to debug the parser itself. So error
reports must _only_ include the (best) partial result(s) and why they failed.

It is very unfortunate though that even in those favorable circumstances
detecting what is the best attempt in order to explain why this one failed
seems to require the same expensive error detection techniques that to detect
user typos.

Indeed, the only way to detect the best attempt is: should this parser had
behaved differently then the whole outcome would have been very different. In
other words, should this parser accept this input as a valid token then we
would have eventually parsed the whole input.

It is hard to think of any trivial trick to make it less awfully explosive that
it sounds, beyond constraining the exploratory search within an 'error budget'.

Many of those ideas come from
http://www.staff.science.uu.nl/~swier101/Papers/1999/SofSem99.pdf[Fast, Error
Correcting Parser Combinators: A Short Tutorial], a XX^th^ century paper.

=== Parser Combinators

Perl does not bow to any rigid formal rule. Parser combinators are appealing
because they make it possible to add new valid constructs without rethinking
the whole grammar.  In addition, they make significantly easier to achieve the
previous objectives.

== The type of the parser

To be clearer, let's write down the usual type of a parser used with
combinators, written in ML:

.Typical parser type
[source,ml]
----
type ('a, 'b) result = 'b * 'a list
type ('a, 'b) parser = 'a list -> ('a, 'b) result list
----

Which reads like this: Calling α the type of the input tokens and β the type
of the parsed inputs, a parser is a function that takes a list of α and
returns a list of pairs composed of a β and a list of α, with the assumptions
that the input list of α is the input stream of tokens to be parsed and that
each output pair are a possible solution, composed of the result and the
remaining list of token to parse. Ideally, a successful top level parser will
thus return a list composed of a single pair (non ambiguity of the outcome)
made of the final result and an empty list (no more input to be parsed). And
when the parser fails to find any way to parse the input it returns a
minimally informative empty list.

Introducing the error budget changes this somewhat: we will try to
artificially force the failing parsers to succeed in order to peek into the
future and try to locate where a change would cause the parsing to succeed.
This means that each individual result must be accompanied by a description of
the (few) changes required to reach that point:

.Parser type with error budget
[source,ml]
----
type ('a, 'b) result = 'b * Corrections.t * 'a list
type ('a, 'b) parser =
  Corrections.t -> 'a list -> ('a, 'b) result list
----

Before looking closer to this new +Corrections.t+ type that would encode the corrections
we must question the usage of a list of results as the return type. First, of
course, a list if over-specified since the order of the possible result is not
important; what we really want here is a set and we use a list only because it
makes our code more terse. But more importantly, one may think that it is not
enough to return an empty list in case of failure since we may also want to
force artificially the failure of a parser; a possibility that we have
dismissed without giving it proper consideration. Indeed, failing to recognize
one form may enable a following parser to succeed. Consider for instance a C++
like language with the erroneous input:

----
class form;
for x = new form(...);
----

Obviously the intent was to write +form x = ...+. Once the parser have
accepted the keyword +for+ as valid without questioning it then it is likely
that the error message porting on what follows will be hard to understand. On
another hand, if the parser also tried to force the failure of the keyword
parser in this location then it will notice that everything would parse
properly henceforth, suggesting a better error message.

The price to pay for testing the failure of successful parsers is obviously high,
though, and not only because of the additional time spent. Returning error
descriptions alongside failures forces us to give up the elegant list of
result as the main return type (indeed, the empty list is not enough any more
to denote failure since we also want to return the updated errors description).

It seems that only in the case of the exclusive alternative this problem will
arise. Should we decide not to implement such a combinator, then the the above
example ``either a keyword or a variable name that is not a keyword'' could
still be written with inclusive alternative at the price of a redundant check:
+is_keyword OR (is_name AND (check (NOT is_keyword))+. In this case we could
explore the failure of the +NOT is_keyword+ check and will find that should
+for+ be a valid variable name then the input would be valid, which will make
a good enough error reporting.

So we will not implement exclusive alternative and will instead explore forced
success of the +check+ parser.

Now, what's this +Corrections.t+ type?

To be able to build a useful error message we must point at the position in
the original stream of tokens where some change had to be made in order to
parse the input stream of tokens (if not in full at least more than without
that change). Recording a position in the original input stream of tokens is
less trivial than it sounds because we are combining the parsers, and one of
the way to combine parsers is to run a parser on the results of another one,
therefore loosing track of the position in the original stream. For generality
let's introduce a new type ɣ to denote a position (could be merely the integer
offset in the original stream or a more elaborate line and column number, or
anything) and let's assume we read from the original stream not only the
tokens but also the positions. And since we are reading the positions from the
input stream we need to introduce a special value for representing the end of
input, that we will call +EOF+:

.Corrections: the type for positions
[source,ml]
----
type 'c position = Coord of 'c | EOF
----

So we need to record all changes that have already occurred (what and where)
and how many changes we are still allowed to do. The ``What'' is limited to
any string description of the parser that we forced to succeed. 

.Corrections: type
[source,ml]
----
type 'c t = ('c position * string) BoundedSet.t
----

where +BoundedSet+ is an unordered container with a maximum capacity (the
maximum amount of changes allowed) and which API will become clearer as we
encounter the few required functions.

Trivially, to add an error at position +pos+ to the correction list, with
message +msg+:

.Corrections: recording a change
[source,ml]
----
let change_at corr pos msg =
  BoundedSet.add corr (pos, msg)
----

Now that we know what corrections look like and that we have to read the
positions alongside the tokens from the input stream, we can finally write the 
definitive parser type:

.Parsers: final type
[source,ml]
----
type ('a, 'b, 'c) result = 'b * ('c Corrections.t) * ('a * 'c) list
type ('a, 'b, 'c) t =
  'c Corrections.t -> ('a * 'c) list -> ('a, 'b, 'c) result list
----

It is sometime unfortunate that OCaml compiler do not preserve the type
variable names throughout a program. In this document though we will stick
with those:

- α (+'a+) stands for the type of input tokens,
- β (+'b+) stands for the type of parsing results,
- ɣ (+'c+) stands for the type of positions in the input stream.

== Base parsers (to be combined)

=== Fail, Return and check.

The simplest parsers that does nothing are +return+ and +fail+. They do not
consume anything from the input but merely return a single result or no result
at all. Given our parser type, here are their implementations:

.Parsers: fail
[source,ml]
----
let fail _corr _unp = []
----

.Parsers: return
[source,ml]
----
let return x corr rest = [x, corr, rest]
----

Those two first parsers perform no type of error detection at all.  But many
other parsers will have to either terminate parsing abruptly (with +fail+) or
add a change to the correction list and proceed, if the error budget is not
exhausted already. We will abstract this in a +fail_or_maybe_not+ function:

.Parsers: fail with success exploration
[source,ml]
----
open Batteries
open Corrections

let fail_or_maybe_not msg x corr ?pos rest =
  let pos = Option.default_delayed (fun () -> next_position rest) pos in
  if BoundedSet.is_full corr then []  (* no more errors permitted so fail for real *)
  else [x, change_at corr pos msg, rest]
----

with:

.Corrections: next_position in a (possibly empty) stream
[source,ml]
----
let next_position = function
  | [] -> EOF
  | (_tok, pos)::_ -> Coord pos
----

Another parser that does not consume any input is the +check+ parser that we
have mentioned earlier. It is actually a combinator since it takes another
parser as parameter. It checks that the given parser succeed but then return
the input stream unchanged (with a +unit+ result). The only thing interesting
is that it explores forcing a success in case the check fails.

.Parsers: check
[source,ml]
----
let check msg p corr rest =
  match p corr rest with
  | [] -> fail_or_maybe_not msg () corr rest
  | _ -> [(), corr, rest]
----

Another parser that will prove useful (despite contributing no value to the
result) especially in coordination with +check+ is the negation:

.Parsers: negation
[source,ml]
----
let not p corr rest =
  match p corr rest with
  | [] -> return () corr rest
  | _ -> fail_or_maybe_not "not" () corr rest
----

So that we could write +check msg (not p)+.

=== Tests

It's is important to have a test infrastructure in place before it's needed.
Given literate programing allows us to mix code and tests at ease we do not
need to get this feature from such a tool as
https://github.com/vincent-hugot/iTeML[qtest] and will use
http://ounit.forge.ocamlcore.org/api-ounit/index.html[oUnit] directly.

Supposing for now that we have all the required printers we can set up a
satisfying environment for tests:

.test: The stage.
[source,ml]
----
open Batteries
open OUnit2
open Corrections
open Parsers

let input_of_string ?(offset=0) s =
  let rec loop n tl =
    if n < 0 then tl else
    loop (n-1) ((s.[n], n + offset) :: tl) in
  loop (String.length s - 1) []

let max_changes = 3
let corr = BoundedSet.make max_changes
let correction_at pos msg =
  let corr = BoundedSet.make max_changes in
  change_at corr pos msg

let no_corr = BoundedSet.make 0
let rest = input_of_string "glop glop pas glop"
let no_input = []

let uniq = function
  | [x, _, _] -> Some x
  | _ -> None

(* version of assert_equal specialized for parser results *)
let assert_same_results ?msg print_output exp actual =
  let print_input = Char.print in
  let print_coord fmt c = Printf.fprintf fmt "offset %d" c in
  let result_printer = print_result print_input print_coord print_output in
  let results_printer = List.print result_printer in
  (* OUnit really should have a assert_same_elements *)
  assert_equal ~printer:(IO.to_string results_printer) ?msg
    (exp |> List.sort compare)
    (actual |> List.sort compare)

let test_suite =
  "tests" >:::
    [ (* ...tests... *) ]

let () =
  run_test_tt_main test_suite
----

That we can test with simple tests for +return+ and +fail+ (which really
does not cause too much worries):

.tests
[source,ml]
----
"return succeed" >:: (
  fun _ctx ->
    assert_same_results Int.print
      [42, no_corr, rest]
      (return 42 no_corr rest)
) ;
"return succeed even at EOF" >:: (
  fun _ctx ->
    assert_same_results Int.print
      [42, no_corr, []]
      (return 42 no_corr no_input)
) ;
"fail fails" >:: (
  fun _ctx ->
    assert_same_results Int.print
      []
      (fail no_corr rest)
) ;
"fail fails even at EOF" >:: (
  fun _ctx ->
    assert_same_results Int.print
      []
      (fail no_corr no_input)
) ;
----

=== Checking for end of stream

Another very useful and basic parser is the one that succeeds on EOF and fails
everywhere else. It is useful to check that the input stream have been consumed
entirely by the preceding parsers).

We may not want tp engage in error detection in this parser: mimicking success
imply pretending the stream stops there, but most input streams could be
trivially declared valid if the stream is cut short (empty string is often
valid for instance). In case of spurious input tokens at the end the error
message shouldn't the error message be trivial enough already? That's
forgetting that we are going to combine parsers, and ``end of stream'' does not
necessarily mean ``end of outer input stream''. It could for instance means the
``end of lines'' in a message header or the ``end of initializers'' in an
initializer list.

We will therefore explore forcing the success of this parser, which implies
cutting the unparsed stream when mimicking success:

.Parsers: checking for EOF
[source,ml]
----
let eof msg corr = function
  | [] -> return () corr []
  | _ as rest ->
    fail_or_maybe_not
      ("spurious "^msg) () corr
      ~pos:(next_position rest) [] (* <1> *)
----

<1>: Here we will restart with +rest = []+. That's the only case when forcing
success also alters the input stream.

And the accompanying test:

.tests
[source,ml]
----
"eof succeed" >:: (
  fun _ctx ->
    assert_same_results Unit.print
      [(), no_corr, []]
      (eof "char" no_corr no_input)
) ;
"eof fails" >:: (
  fun _ctx ->
    assert_same_results Unit.print
      []
      (eof "char" no_corr rest)
) ;
"eof suggests truncation" >:: (
  fun _ctx ->
    assert_same_results Unit.print
      [(), correction_at (Coord 0) "spurious char", []]
      (eof "char" corr rest)
) ;
----

=== First non trivial parser

The more general of parsers that do consume some input is the +cond+ parser,
which tries to recognize a condition on the next token (for instance that it
is equal to a given value). So +cond+ is a function that takes a predicate on
token and returns a parser that, when given this token, returns it (and
consumes it), or otherwise fails (with a message describing what it was
looking for, in case we have to build an error message for that step later
on).

Now that we know the type, writing the code is rather easy:

.Parsers: the cond parser
[source,ml]
----
let cond msg f x corr rest =
  let res, chg = (match rest with
  | [] ->
    [], [x (* <1> *), change_at corr EOF msg, rest]
  | (tok, _pos)::rest' when f tok ->
    [tok, corr, rest'], []
  | (_tok, pos)::rest' ->
    [], [x, change_at corr (Coord pos) msg, rest']) in
  if BoundedSet.is_full corr || chg = [] then res
  else List.rev_append res chg
----

So for each possible case (+EOF+, +f+ succeeds or +f+ fails) we prepare both
the result and the altered result and return both whenever possible.

<1> Here we need an example value +x+ of type β in order to change
the outcome of a failure at end of input. Which value exactly is not really a
concern since only its type matters (although the error message could print it
as an example, as OCaml compiler does when complaining about an incomplete
pattern matching.

It is possible to build many simpler and more convenient parsers on top of
+cond+, such as +item+ which expects a specific token in the input:

.Parsers: the item parser
[source,ml]
----
let item ?(what="item") x =
  cond ("missing "^what) ((=) x) x
----

.tests
[source,ml]
----
"item canonical success" >:: (
  fun _ctx ->
    assert_same_results Char.print
      ['g', no_corr, List.tl rest]
      (item 'g' no_corr rest)
) ;
"item canonical failure" >:: (
  fun _ctx ->
    assert_same_results Char.print
      []
      (item 'X' no_corr rest)
) ;
"item fails at EOF" >:: (
  fun _ctx ->
    assert_same_results Char.print
      []
      (item 'g' no_corr no_input)
) ;
"item error exploration" >:: (
  fun _ctx ->
    assert_same_results Char.print
      ['X', correction_at (Coord 0) "missing item", List.tl rest]
      (item 'X' corr rest)
) ;
----

== Modifying parsers result

Before going too far we need to introduce functions to alter a parser result (equivalent of map, fold, filter...) and come up with a convenient syntax for those since they are going to be used prevalently.

.Parsers: applying a function to all results of a parser
[source,ml]
----
let map p f corr rest =
  p corr rest |>
  List.map (fun (x, corr, rest) -> f x, corr, rest)
----

The order of parameters is important so that +map p f+ is itself a parser.
An infix operator makes it even more convenient:

.Parsers: infix operator for map
[source,ml]
----
let (>>:) = map
----


== Combinators

The three first combinators to consider are the succession of two given
parsers (binding), the alternative of two parsers, and the pipe of one parser
result into the input of another one.

Notice that since we are now merely combining parsers we do not have to care
about error correction any more: only the base parsers need to pretend
succeeding when they fail.

.Parsers: binding two parsers
[source,ml]
----
let bind p1 p2 corr rest =
  match p1 corr rest with
  | [] -> [] (* if p1 fails there is no need to try p2 *)
  | res_list1 -> (* for each possible result, try to continue parsing with p2 *)
    List.fold_left (fun res_list' (x1, corr1, unp1) ->
      match p2 corr1 unp1 with
      | [] -> res_list'
      | res_list2 ->
        (* The final result set is the product of each
           result of p1 with all following results of p2 *)
        List.fold_left (fun res_list'' (x2, corr2, unp2) ->
          ((x1,x2), corr2, unp2)::res_list'') res_list' res_list2)
      [] res_list1
----

This parser being used to connect successive parsers we'd rather have a shorter infix alternative for +bind+:

.Parsers: infix operator for bind
[source,ml]
----
let (++) p1 p2 = bind p1 p2
----

Also, we will often discard the result of one parser. For instance when parsing
delimiters the only information is that the parser succeeds (there is a
delimiter) but there is no value to attach to that success. Also when using
the +check+ parser, which purpose is really not its return value. So here are
three variants of bind: one that ignores the result of +p1+, one that ignores
the result of +p2+, and one that ignore both (returning +()+):

.Parsers: other convenient infix operators
[source,ml]
----
let (+-) p1 p2 = p1 ++ p2 >>: fst
let (-+) p1 p2 = p1 ++ p2 >>: snd
----

Now let's test we can indeed sequence parsers:

.tests
[source,ml]
----
"Can parse a sequence" >:: (
  fun _ctx ->
    let ab = input_of_string "ab" in
    assert_same_results (Tuple2.print Char.print Char.print)
      [('a', 'b'), no_corr, []]
      ((item 'a' ++ item 'b') no_corr ab) ;
    assert_same_results Char.print
      ['a', no_corr, []]
      ((item 'a' +- item 'b') no_corr ab)
) ;
----

The second most useful combinator is the alternative:

.Parsers: alternative
[source,ml]
----
let any p1 p2 corr rest =
  let res_list1 = p1 corr rest in
  let res_list2 = p2 corr rest in
  List.rev_append res_list1 res_list2

let (|||) = any
----

Notice that results are really sets not list, so the order in which the
alternatives are listed does not matter.  Notice also that this is not an
exclusive alternative: if both +p1+ and +p2+ can parse them both will
contribute a result to the result list. As discussed in the beginning we do
not enforce that if +p1+ succeeds then +p2+ must fail nor the other way
around. If this is wanted though then it is easy enough to write:

.Parsers: exclusive alternative
[source,ml]
----
let either p1 p2 =
  (check "??1" (not p2) -+ p1) ||| (check "??2" (not p1) -+ p2)

let (|/|) = either
----

With sequences and alternatives we can start writing some interesting tests:

.tests
[source,ml]
----
"any: 'a' or 'b' but not 'z'" >:: (
  fun _ctx ->
    let a_or_b = item 'a' ||| item 'b' in
    assert_same_results Char.print
      ['a', no_corr, []]
      (a_or_b no_corr (input_of_string "a")) ;
    assert_same_results Char.print
      ['b', no_corr, []]
      (a_or_b no_corr (input_of_string "b")) ;
    assert_same_results Char.print
      []
      (a_or_b no_corr (input_of_string "z")) ;
    assert_same_results Char.print
      ['a', correction_at (Coord 0) "missing item", [] ;
       'b', correction_at (Coord 0) "missing item", []]
      (a_or_b corr (input_of_string "z"))
) ;
----

Finally, it is often useful to have a first parser output a list of results
which are then feed into another parser. Think for example: splitting character
stream into keywords and then parsing those keywords.

.Parsers: pipe
[source,ml]
----
let pipe p1 p2 corr rest =
  let res_list1 = p1 corr rest in
  List.fold_left (fun res_list (x1, corr1, unp1) ->
    (* x1 is supposed to be a list *)
    let res_list2 = p2 corr1 x1 in
    (* We want the result of p2 with the remained of p1! *)
    List.fold_left (fun res_list (x2, corr2, _unp2) ->
      (* Notice that we do not care about unp2: if the user want to
         make sure that p2 parses all of x then if must make p2 checks this. *)
      (x2, corr2, unp1)::res_list)
      res_list res_list2)
    [] res_list1
----

== Repeating parsers

Binding several parsers allows us to get several values from the input stream but it would be more useful to be able to repeat a given parser.

Before that, a special case of repetition will prove very useful: having zero or one occurrence of +p+:

.Parsers: zero or one
[source,ml]
----
let optional ~def p = p ||| return def
----

The +repeat+ combinator is a swiss-army knife for all variants of repetitions,
requiring a parser +p+ to succeed from +min+ to +max+ times consecutively, with
an optional additional parser +sep+ for a separator in between +p+ occurrences.
It returns a list of all values returned by the successive +p+.

But allowing +min+ to be +0+ (and making it the default value) we expect to 
cut down on the +optional (repeat p)+ that we would have otherwise.

.Parsers: repetition of a parser
[source,ml]
----
let rec repeat ?(sep=return ()) ?(min=0) ?max p corr rest =
  if max = Some 0 then (
    if min = 0 then return [] corr rest
    else fail corr rest
  ) else (
    let pred_ma = match max with None -> None
                               | Some m -> Some (m-1) in
    match min with 0 ->
      (* we may stop here or continue *)
      (optional ~def:[] (repeat ~sep ~min:1 ?max p)) corr rest
                | 1 ->
      (* at least one more, everything else optional *)
      ((p ++ optional ~def:[]
                 (sep -+ (repeat ~sep ~min:1 ?max:pred_ma p))) >>:
        fun (x, xs) -> x::xs) corr rest
                | _ ->
      (* above that, repetition is mandatory *)
      ((p +- sep ++ repeat ~sep ~min:(min-1) ?max:pred_ma p) >>:
        fun (x, xs) -> x::xs) corr rest
  )
----

Notice there are two conditions that terminate the recursion: +max+ reaching
+0+ (no more occurrences permitted) or, when +min > 0+, a failure of +p+.

We can easily define the greedy version of +repeat+ (that is, a version that
swallows as many +p+ occurrences as present in the input stream) using check:

.Parsers: greedy repetition
[source,ml]
----
let repeat_greedy ?(sep=return ()) ?min ?max p =
  repeat ~sep ?min ?max p +- check "extraneous" (not (sep -+ p))
----

.tests
[source,ml]
----
"repetition: canonical successes" >:: (
  fun _ctx ->
    let aaab = input_of_string "aaab" in
    assert_same_results (List.print Char.print)
      [['a';'a';'a'], no_corr, input_of_string ~offset:3 "b" ;
       ['a';'a'],     no_corr, input_of_string ~offset:2 "ab" ;
       ['a'],         no_corr, input_of_string ~offset:1 "aab" ;
       [],            no_corr, aaab]
      (repeat (item 'a') no_corr aaab) ;
    (* Same with min=2 *)
    assert_same_results (List.print Char.print)
      [['a';'a';'a'], no_corr, input_of_string ~offset:3 "b" ;
       ['a';'a'],     no_corr, input_of_string ~offset:2 "ab"]
      (repeat ~min:2 (item 'a') no_corr aaab) ;
    (* Testing max=2 *)
    assert_same_results (List.print Char.print)
      [['a';'a'],     no_corr, input_of_string ~offset:2 "ab" ;
       ['a'],         no_corr, input_of_string ~offset:1 "aab" ;
       [],            no_corr, aaab]
      (repeat ~max:2 (item 'a') no_corr aaab) ;
    (* Now with min and max *)
    assert_same_results (List.print Char.print)
      [['a';'a'],     no_corr, input_of_string ~offset:2 "ab" ;
       ['a'],         no_corr, input_of_string ~offset:1 "aab"]
      (repeat ~min:1 ~max:2 (item 'a') no_corr aaab) ;
    (* min = max *) 
    assert_same_results (List.print Char.print)
      [['a';'a'],     no_corr, input_of_string ~offset:2 "ab"]
      (repeat ~min:2 ~max:2 (item 'a') no_corr aaab)
) ;
----

== Miscellaneous

=== BoundedSet

We still have to provide an implementation for our set of fixed maximum size.
The simplest implementation is that of a list with a current size:

.BoundedSet: type
[source,ml]
----
type 'a t =
  { size : int ;
    max_size : int ;
    items : 'a list }
----

With the trivial constructor:

.BoundedSet: constructor
[source,ml]
----
let make max_size =
  { size = 0 ; max_size ; items = [] }
----

And the only two operations we've met so far:

.BoundedSet: operations
[source,ml]
----
let is_full t = t.size >= t.max_size

let add t x =
  { t with size = t.size + 1 ;
           items = x::t.items }
----

=== Printers

If there is something annoying about OCaml it's the lack of default printers
for types. +Batteries+ provides +dump+ but it is oblivious to constructors so
the result is not pretty. So let's write our own.

It would be best to provide formatters instead of mere printers to benefit from
automatic typesetting but unfortunately +Batteries+ support for those is
minimal so it's better to forget about formatters to cut down on typing.

.BoundedSet: printer
[source,ml]
----
open Batteries

let print print_value fmt t =
  List.print print_value fmt t.items
----

.Corrections: printers
[source,ml]
----
open Batteries

let print_position print_coord fmt = function
  | EOF -> String.print fmt "end of input"
  | Coord c -> print_coord fmt c

let print_correction print_coord fmt (pos, msg) =
  Printf.fprintf fmt "%s at %a"
    msg
    (print_position print_coord) pos

let print_corrections print_coord fmt corr =
  BoundedSet.print (print_correction print_coord) fmt corr
----

.Parsers: printers
[source,ml]
----
open Batteries

let print_result print_input print_coord print_output fmt (x, corr, rest) =
  Printf.fprintf fmt "(output=%a,corr=%a,rest=%a)"
    print_output x
    (print_corrections print_coord) corr
    (List.print (fun fmt (tok, _pos) -> print_input fmt tok)) rest
----

