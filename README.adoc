// vim:filetype=asciidoc expandtab spell spelllang=en ts=2 sw=2
= Resumable Parser Combinators with error detection
rixed@happyleptic.org
v0.1, 2015-10-27
:toc:
:numbered:
:icons:
:lang: en
:encoding: utf-8

== What is this?

This document describes the implementation of a library performing text
parsing according to a technique that is called
https://en.wikipedia.org/wiki/Parser_combinator[parser combinators] because the
parser for a given grammar is build combining simpler parsers. This technique
is fashionable although old and slow for the reason that it is simple and
permissive.

This is also an example of literate programming; in case the notations used in
this document are unclear you can read about them in
http://rixed.github.io/portia/notations.html[this document].

== Requirements

=== A N+1^th^ parser to rule them all

Along the years I've often written small dedicated parsing libraries, either
using lex+yacc approach for well behaved syntaxes or custom made combinatoric
parsers because they are fun to play with and more flexible. My needs ranged
from parsing configuration files, parsing programming languages, parsing
natural languages, parsing networking protocols...

This parser is meant to be flexible enough to accommodate all those needs, when
speed is not an issue.

=== Parsing binary

Although most of the times one wants to parse text there are cases when the
need arises to parse binary messages (such as when parsing some networking
protocols). Therefore parsed input tokens must not be bound to characters.

=== Parsing recursively

I want to parse as much as possible from perl and other such footgun languages
(without executing them).  Perl has +eval+ on strings. Therefore parsing must
not stop as soon as we reach a string literal but instead recurse and try to
parse that string. It must therefore be possible to write such a recursive set
of rules.

=== Parsing with gaps

For the same reason I want to be able to parse as much as possible of an input
even if some parts of it is (still) missing. This is useful both to parse
string fragments into code but also to parse a networking stream despite
missing packets.

=== Best effort

It will not always be possible to know for sure the type of all symbols. In
that case we want to present all possible alternatives as the result, rather
than stopping the parse or selecting the most probable one.

=== Resumable parsers

The parser must be usable for parsing large messages either received from
the network or stored on a file, without having to buffer everything.  Input
tokens must therefore be consumed as they arrive, and the parser must "return"
when it has processed the given input as much as possible, and be resumable
later on when more data is available.

For this, +call_cc+ would help tremendously to freeze the state of affairs and
return it to the original caller.  Without that facility, though, alternatives
do exist:

A conventional method to achieve something similar is to turn our API (aka our
types) inside out: instead of taking a stream of input tokens and returning a
result, parsers could take the next item and return, along with each result, a
next-step parser to apply to the next token. This is rather inconvenient,
though.

Alternatively, threading is another way to freeze ones stack: a parser waiting
for input could just be waiting for a conditional variable, or the input stream
could be a `mailbox variable` kind of queue, etc. All this amount to relying on
the kernel to freeze the parser and resume it later.

We might want to use those parsers in an environment where using POSIX threads
is not an option, though (such as: in a microkernel).  In that case lightweight
threads (akin to gnupth) could work, but that's still a huge constraint on the
environment. Instead, closure-based threads, a variety of cooperative threads
where a thread context is saved in a function closures (and that are also
sometime referred to as "lightweight threads") are cheap and does not depend on
OS support ; for this reason they are available in many shapes and forms. The
downside is that the API needs to accommodate for those (basically, each parser
must return a future value rather than a value). But once this abstraction is
in place then one is free to use it for any variant of threads or make it a
bypass. That's thus what this library will be using, at the cost of a bit of
functorization.

=== Error detection

Error detection must be an option. The simplest method to reach this goal would
be to have an 'error budget', and try different outcomes at every step to look
the combination of alternatives that parse the most of the input stream.

It is hard to make this technique less awfully expensive than it sounds.

Setting this error budget to zero would effectively turn off the feature.

Instead of a global error budget, one may prefer to have a maximum error rate.

Many of those ideas come from
http://www.staff.science.uu.nl/~swier101/Papers/1999/SofSem99.pdf[Fast, Error
Correcting Parser Combinators: A Short Tutorial], a XX^th^ century paper.

=== Error reporting

Although this is related to error detection, error reporting is a requirement
on it own.  Indeed, a parser could do a good job at correcting typos but still
be unable to report a meaningful error message when it fails to process the
input tokens.

=== Parser Combinators

Natural languages (and many runtime typed programming languages too) do not bow
to any rigid formal grammar. Parser combinators are appealing because they make
it possible to add new valid constructs without rethinking the whole grammar;
thus permitting to build a good enough parser iteratively.

== The type of the parser

To be clearer, let's write down the usual type of a parser used with
combinators, written in ML:

.Typical parser type
[NOTE]
[source,ml]
----
type ('a, 'b) parser = 'a list -> ('b * 'a list) list
----

Which reads like this: Calling α (+'a+) the type of the input tokens and β
(+'b+) the type of the result, a parser is a function that takes a list of α
and returns a list of pairs composed of a β and a list of α, with the
assumptions that the output is a list of all possible solutions, composed of
the result of the parse and the list of tokens that remain to be parsed.
Ideally, a successful top level parser will thus return a list composed of a
single pair (non ambiguity of the outcome) made of the final result and an
empty list (the whole input has been consumed).

For resumable parsing in a possibly threading context we need to
introduce the +α ct+ type (for a future value of type +α+), and make the
input stream of tokens a possibly blocking function returning the next item,
also turning our +Parsers+ module into a functor depending on what mechanism we
plan to use for threading between parsers and token intake.

Having now a functor and an abstract stream brings the question whether to keep
the type for tokens (α) universal or rather make it existential (an abstract
but single type). Keeping it universal makes it easier to combine parsers
(especially: we can devise such combinators that feed a parser with something
else than tokens, such as the result of another parser). But on the down side
it would force the user to hand us a stream type that can handle any type,
which is a strong constraint to bear with ; for one, it prevents the stream
implementation to look at the actual values. This would prove too inconvenient
given we will enrich the stream with positions. We thus change the type of the
stream to return an existential rather than universal type:

.Parsers.ml: functor to parametrize over the threading mechanism
[source,ml]
----
open Batteries

module type CONFIG = sig
  type token
  (* ...Parser configuration... *)
end

module type S = sig
  include CONFIG

  (* ...Parser signature... *)
end

module Make (Conf : CONFIG) :
  S with type token = Conf.token
  (* ...parser public type constraints... *) =
struct
  include Conf

  (* ...Parser library... *)
end
----

Due to functorization we have to explicitly provide a signature for the
result of +Make+ so that we can use the resulting parser as input of further
functors.

The configuration must thus provides not only the actual type for frozen
computations (aka future values) but also a way to wrap a value into such a
`future value` and a way to pipe one `thread` into another, both operations
typically called `return` and `bind` but here prefixed with +ct_+ because we
reserve those names for parser combinators:

.Parser configuration
[source,ml]
----
type 'a ct
val ct_return : 'a -> 'a ct
val ct_bind : 'a ct -> ('a -> 'b ct) -> 'b ct
----

Thus the possibly blocking input mechanism:

.Parser configuration with possible threading
[NOTE]
[source,ml]
----
type stream
val take : stream -> (token ParsersMisc.stream_item * stream) ct
----

With the +stream_item+ type being like an +option+ type with more specific
constructors, defined in a separate module for fear of circular dependencies:

.ParsersMisc.ml: type of stream value
[source,ml]
----
type 'a stream_item = Item of 'a | EndOfStream
----

Notice that this +stream+ container must be free of side effects to the extend
that any token read from it in one place must still be available for reading
from previously stored streams. That is why +take+ returns both the next token
and the next (shorter) stream. In other words it must be a persistent data
structure.

For convenience better not keep it secret where our +Parsers+ takes its types
from:

.parser public type constraints
[source,ml]
----
and type 'a ct = 'a Conf.ct
and type stream = Conf.stream
----

Thus a parser now has this shape:

.Resumable parser type
[NOTE]
[source,ml]
----
type 'b parser = stream -> ('b * stream) list ct
----

With this API, when the parser fails to find any way to parse the input it
returns a minimally informative empty list. Introducing the error budget
changes this somewhat: we will try to artificially force the failing parsers to
succeed in order to sneak into that alternate reality and try to locate where a
change would lead to a drastically better outcome. This means that each
individual result must be accompanied with a description of the (few) changes
required to reach that point:

.Parser type with error detection
[NOTE]
[source,ml]
----
type 'b parser =
  ParsersCorrections.t -> stream -> ('b * ParsersCorrections.t * stream) list ct
----

Before taking a closer look at this new +ParsersCorrections.t+ type that would
encode the corrections we must question the usage of a list of results as the
return type.  Firstly, a list is over-specified since the order of the possible
results is not important; what we really want here is a set and we use a list
only because it makes our code more terse. More importantly an empty list to
signal failure seems not enough to explore the artificial _failure_ of parsers
(because we need to store that correction somewhere).

Consider for instance this excerpt from a fictitious programming language:

----
class form;
for x = new form(...);
----

Obviously the intent was to write +form x = ...+. Imagine the rule to parse the
second line is +is_keyword XOR is_name+. Once the parser have accepted the
keyword +for+ as valid without questioning it then it is likely that the error
message porting on what follows will be hard to understand. On another hand, if
the parser also tried to force the failure of the keyword parser in this
location then it will notice that everything would parse properly henceforth,
suggesting a better error message. So it seems beneficial to return that
failure as a correction and move on to next token.

The price to pay for testing the failure of successful parsers is obviously
high, though, and not only because of the additional time spent. Returning
error descriptions alongside failures forces us to give up the elegant list of
result as the main return type.

But it seems that this problem arises only when we make use of the exclusive
alternative.  Should we decide not to implement such a combinator, then the
above example ``either a keyword or a variable name that is not a keyword''
could still be written with inclusive alternative at the price of redundant
checks: +(is_keyword AND (check (NOT is_name))) OR (is_name AND (check (NOT
is_keyword)))+. In this case we could explore the failure of the checks and
notice that if +for+ were a valid variable name then the input would be valid,
which will make a much better error message.

So we will not implement exclusive alternative and will instead explore forced
success of the +check+ parser. Hence, we turned exploring failure into
exploring success and saved our list as the return type.

Now, what's this +ParsersCorrections.t+ type?

To be able to build a useful error message we must point at the position in
the original stream of tokens where some change had to be made in order to
parse the input stream of tokens (if not in full at least more than without
that change). What constitutes a position depends on the nature of the tokens.
The obvious offset since the beginning might not always be appropriate and
it's probably better to leave it open to the user. Let's therefore assume that
both tokens and positions are read from the input stream.

In addition to the location a mere description of the parser that we forced
to succeed (as a string) completes the +ParsersCorrection.t+. For the position
we conveniently reuse the stream output as it can already encode both the
position and the special +EOF+ position:

.ParsersCorrections.ml: type
[source,ml]
----
open ParsersMisc
type 'c t = ('c stream_item * string) ParsersBoundedSet.t
----

where +ParsersBoundedSet+ is an unordered container with a maximum capacity (the
maximum amount of changes allowed) and which API will become clearer as we
encounter the few required functions.

Trivially, to add an error at a given position to the correction list, with
message +msg+:

.ParsersCorrections.ml: recording a change
[source,ml]
----
let change_at c postok m =
  ParsersBoundedSet.add c (postok, List.hd m)
----

Now that we know what corrections look like and that we have to read the
positions alongside the tokens from the input stream, we can write a better
type for the parser:

.Parser type with error correction
[NOTE]
[source,ml]
----
type 'b possible_result =
  'b * ((position * token) ParsersCorrections.t) * stream
type 'b t =
  (position * token) ParsersCorrections.t -> stream ->
  'b possible_result list ct
----

The type +position+ have to be supplied by the functor configuration and now we
have the final type for +stream+/+take+:

.Parser configuration: now also supplying position
[source,ml]
----
type position
type stream
val take : stream -> ((position * token) ParsersMisc.stream_item * stream) ct
----

.parser public type constraints
[source,ml]
----
and type position = Conf.position
and type stream = Conf.stream
----

We are not done yet. Above we saved the list as a container for the possible
solutions, but this still left us with an empty list when no solution could be
found, from which it's not possible to devise an informative error message!

In addition to the cumulative list of all solutions a parser should also return
an aggregated value containing the "best" error found.

What we call the "best" error is the error that caused the parser to give up
(return +[]+) the later in the input stream, measured by the position of the
token. We thus need another function from the configuration:

.Parser configuration: comparator for positions
[source,ml]
----
val cmp_position : position -> position -> int
----

An error is made of the location in the stream where the parsing stopped and
the stack of things the parser was trying to build:

.error type:
[source,ml]
----
type error =
  { where : (position * token) ParsersMisc.stream_item ;
    what : string list }
----

We can update the current best error from another stream item and stack of
messages with this simple function:

.keeping track of the best error
[source,ml]
----
let new_error pt m = function
  | None -> Some { where = pt ; what = m }
  | Some err as e -> (
    let open ParsersMisc in
    match pt, err.where with
    | EndOfStream, _ ->
      Some { where = pt ; what = m }
    | Item (pos, _), Item (best_pos, _) when cmp_position pos best_pos > 0 ->
      Some { where = pt ; what = m }
    | _ -> e)
----

With the idea that a stack of messages describing the context is maintained
from one parser to the next as the context gets deeper. Therefore, every parser
must accept this current stack as an additional input.

So that the new (and final) type for parsers expands to:

.final parser type
[source,ml]
----
(* ...error type... *)

type 'b possible_result =
  'b * ((position * token) ParsersCorrections.t) * stream

type 'b t =
  string list -> error option ->
  (position * token) ParsersCorrections.t -> stream ->
  (error option * 'b possible_result list) ct
----

That we want both in the implementation and the signature:

.Parser library
[source,ml]
----
(* ...final parser type... *)
(* ...keeping track of the best error... *)
----

.Parser signature
[source,ml]
----
(* ...final parser type... *)
----

That's a lot of inputs. For simplicity and conciseness those parameters will
always be given the same one letter names:

- +m+ for the stack of messages describing the context (of type +string list+);
- +e+ for the optional +error+;
- +c+ for the +ParsersCorrections.t+;
- +s+ for the +stream+;
- +x+ for a +token+;
- +p+ for a parser (of type +t+);
- +r+ for a list or possible results (of type +'b possible_result list+).

The output itself, +(error option * 'b possible_result list) ct+ fits combining
parsers but may be a bit uneasy to handle for the end user. This function turn
it into a more manageable +result+ type:

.Parser library: building a final result from possible results
[source,ml]
----
let to_result (e, r) =
  (* If we have a single solution then that's the one! *)
  match r with
  | [ b, c, _s ] ->
    if ParsersBoundedSet.is_empty c then Ok b
    else Bad (Approximation (b, c))
  | [] ->
    Bad (NoSolution e)
  | lst ->
    Bad (Ambiguous (List.map (fun (b, c, _s) -> b, c) lst))
----

of type:

.Parser signature
[source,ml]
----
val to_result : error option * 'b possible_result list ->
                ('b, 'b failure) result
----

with:

.final parser type: many ways to fail
[source,ml]
----
type 'b failure =
  | Approximation of ('b * (position * token) ParsersCorrections.t)
  | Ambiguous of ('b * (position * token) ParsersCorrections.t) list
  | NoSolution of error option
----

Notice that we pay no attention to whether the stream has been emptied or not.
If one want to reach the end of the input stream then that must be part of the
parser (see +eof+).

It will come handy to have a configuration that's as simple as possible, with
no threading going on, for those cases where we do not need resumable parsers;
for instance when testing. Since there is no threading all the input has to be
already available and can thus be passed using a mere list.

The +SimpleConfig+ serves this purpose:

.Parsers.ml: simple configuration for non-resumable parsers
[source,ml]
----
open ParsersMisc
module SimpleConfig
  (Token : sig
    type t
    val print : 'o BatInnerIO.output -> t -> unit
  end) =
struct
  type 'a ct = 'a
  type token = Token.t
  let print_token = Token.print
  type position = int
  let cmp_position = Int.compare
  let print_position fmt p =
    Printf.fprintf fmt "offset %d" p
  type stream = (position * token) list
  let print_stream fmt = List.print (fun fmt (_p, t) ->
    Printf.fprintf fmt "%a" print_token t) fmt
  let take = function
    | [] -> EndOfStream, []
    | x :: rest -> Item x, rest
  let ct_return x = x
  let ct_bind x f = f x
  (* ...other SimpleConfig definitions... *)
end
----

We will devise a more elaborate configuration for +LWT+ later on.

== Base parsers (to be combined)

=== Fail, Return and check.

The simplest parser that does nothing is +return+. It does not
consume anything from the input but merely return a single result:

.Parser library: return
[source,ml]
----
let return x _m e c s = ct_return (e, [x, c, s])
----

A similarly simple one is the parser that always fail:

.Parser library: fail
[source,ml]
----
let fail _m e _c _s = ct_return (e, [])
----

with signatures:

.Parser signature
[source,ml]
----
val return : 'b -> 'b t
val fail : 'b t
----

Those two first parsers perform no error correction at all.  But many other
parsers will have to either terminate parsing abruptly (with +fail+) or add a
change to the correction list and proceed, if the error budget is not
exhausted already. We will abstract this in a +fail_or_maybe_not+ function:

.Parser library: fail with success exploration
[source,ml]
----
open ParsersCorrections

let fail_or_maybe_not x (* <1> *) ?pos_from m e c s =
  ct_bind
    (take (Option.default s pos_from))
    (fun (pt, _s') ->
      if ParsersBoundedSet.is_full c then (
        (* no more errors permitted so fail for real *)
        fail m (new_error pt m e) c s
      ) else (
        (* Here we insert x in the stream ;
           Shall we also try to replace postok with x?
           In any case beware than s maybe end_of_stream.
           TODO: two types of correction: replace and insert *)
        (* Note that corrections still count as errors because there is no
           guarantee that we will keep track of them: *)
        return x m (new_error pt m e) (change_at c pt m) s))
----

<1> Here we need an example value +x+ of type β in order to change the outcome
of a failure. Which value exactly is not really a concern since only its type
matters (although the error message could print it as an example, as OCaml
compiler does when complaining about an incomplete pattern matching).

Notice that the +pos_from+ parameter allows the caller to set the position in
addition to the message of the correction. By default the position will be
taken from the passed stream (+rest+).

Another parser that does not consume any input is the +check+ parser that we
have mentioned earlier. It is actually a combinator since it takes another
parser as parameter. It checks that the given parser succeed but then return
the input stream unchanged (with a +unit+ result). The only thing interesting
is that it explores forcing a success in case the check fails.

.Parser library: check
[source,ml]
----
let check p m e c s =
  let m = "check"::m in
  ct_bind (p m e c s) (function
    | e', [] -> fail_or_maybe_not () m e' c s
    | e', _ -> return () m e' c s)
----

.Parser signature
[source,ml]
----
val check : 'b t -> unit t
----

Another parser that will prove useful (despite contributing no value to the
result) especially in coordination with +check+ is the negation:

.Parser library: negation
[source,ml]
----
let nay p m e c s =
  let m = "not"::m in
  ct_bind (p m e c s) (function
    | e', [] -> return () m e' c s
    | e', _ -> fail_or_maybe_not () m e' c s)
----

So that we could write +check m (nay p)+.

.Parser signature
[source,ml]
----
val nay : 'b t -> unit t
----

=== Tests

It is important to have a test infrastructure in place before it's needed.
Given literate programing allows us to mix code and tests at ease we do not
need to get this feature from such a tool as
https://github.com/vincent-hugot/iTeML[qtest] and will use
http://ounit.forge.ocamlcore.org/api-ounit/index.html[oUnit] directly.

Supposing for now that we have all the required printers we can set up a
satisfying environment for tests:

.test.ml: the stage.
[source,ml]
----
open Batteries
open OUnit2
open ParsersMisc
open ParsersCorrections

module P = Parsers.Make (Parsers.SimpleConfig (Char))
(* ...other tested modules... *)
open P

let stream_of_string s =
  let rec loop n tl =
    if n < 0 then tl else
    loop (n-1) ((n, s.[n]) :: tl) in
  loop (String.length s - 1) []

let max_changes = 3
let corr = ParsersBoundedSet.make max_changes
(* TODO: two types of correction: replace and insert *)
let correction_at postok m =
  let c = ParsersBoundedSet.make max_changes in
  change_at c postok [ m ]

let no_corr = Parsers.no_error_correction
let rest = stream_of_string "glop glop pas glop"
let no_input = []

(* ...other global functions or types for testing... *)

let uniq = function
  | [x, _, _] -> Some x
  | _ -> None

(* version of assert_equal specialized for parser results *)
let assert_same_results ?msg print_output exp got_ =
  ct_bind got_ (fun got ->
    let printer =
      IO.to_string (print_possible_results print_output) in
    let cmp (exp_err, exp) (act_err, got) =
      let same_err =
        match exp_err, act_err with
        | None, _ ->
          (* Many times we do not want to guess the errors (for instance
             when the parser actually succeeds): *)
          true
        | Some exp_err, Some act_err ->
          (* Unless we give a deep exp_err we want to compare only the heads: *)
          exp_err.where = act_err.where &&
          (match exp_err.what, act_err.what with
          | [exp_head], act_head::_ ->
            0 = compare exp_head act_head
          | exp_what, act_what ->
            0 = compare exp_what act_what)
        | exp, act ->
          0 = compare exp act in
      same_err &&
      0 = compare (List.sort compare exp)
                  (List.sort compare got) in
    ct_return (
      (* OUnit really should have an assert_same_elements *)
      assert_equal ~printer ~cmp ?msg exp got)) |>
  ignore

let () =
  run_test_tt_main (
    "test helpers" >:::
      [ "stream_of_empty" >:: (
          fun _ctx ->
            assert_equal ~printer:string_of_int
              0 (List.length (stream_of_string ""))) ;
        "stream_of_string basic" >:: (
          fun _ctx ->
            assert_equal ~printer:string_of_int
              2 (List.length (stream_of_string "ab"))) ;
        "(no) corrections allowed" >:: (
          fun _ctl ->
            assert_bool "no_corr is full"
              (ParsersBoundedSet.is_full no_corr) ;
            assert_bool "corr is not full"
              (not (ParsersBoundedSet.is_full corr))) ;
        ]) ;
  run_test_tt_main (
    "tests" >:::
      [ (* ...tests... *) ])
----

Notice that we have to force the type of +assert_same_results+ to be +unit+
(with +ignore+) otherwise it would be +unit P.ct P.ct+, which should be
demonstrably equivalent to +unit+ given +SimpleConfig+ but still makes the
compiler to grumble.

Let's warm this with simple tests for +return+ and +fail+ (which really does
not cause too much worries):

.tests
[source,ml]
----
"return succeed" >:: (
  fun _ctx ->
    assert_same_results Int.print
      (None, [42, no_corr, rest])
      (return 42 [] None no_corr rest)
) ;
"return succeed even at EOF" >:: (
  fun _ctx ->
    assert_same_results Int.print
      (None, [42, no_corr, []])
      (return 42 [] None no_corr no_input)
) ;
"fail fails" >:: (
  fun _ctx ->
    assert_same_results Int.print
      (None, [])
      (fail [] None no_corr rest)
) ;
"fail fails even at EOF" >:: (
  fun _ctx ->
    assert_same_results Int.print
      (None, [])
      (fail [] None no_corr no_input)
) ;
----

=== Checking for end of stream

Another very useful and basic parser is the one that succeeds on EOF and
fails everywhere else. It is useful to check that the input stream have been
consumed entirely by the preceding parsers.

TODO: the main usage is to remove all the partial solutions from the final
result. Maybe we should provide a function for that, and get rid of this
and from_pos in fail_or_maybe_not and empty_stream?

We may not want to engage in error detection in this parser: mimicking success
implies pretending the stream stops there, but most input streams could be
trivially declared valid if the stream is cut short (empty string is often
valid for instance). In case of spurious input tokens at the end shouldn't the
error message be trivial enough already? This is indeed tempting, as checking
forcing +eof+ to succeed forces us to require an empty_stream from the
configuration:

.Parser library: checking for EOF
[source,ml]
----
open ParsersMisc
let eof m e c s =
  let m = "eof"::m in
  ct_bind (take s) (function
    | EndOfStream, s' ->
      return () m e c s'
    | _ ->
      fail_or_maybe_not () ~pos_from:s
        m e c empty_stream (* <1> *))
----

<1> Here we will restart with +rest = []+. That's the only case when forcing
success also alters the input stream. That's also the only use for
+empty_string+.

.Parser signature
[source,ml]
----
val eof : unit t
----

This uncalled for +empty_stream+ must therefore be provided by the parser
configuration:

.Parser configuration: empty stream
[source,ml]
----
val empty_stream : stream
----

.other SimpleConfig definitions
[source,ml]
----
let empty_stream = []
----

And the accompanying tests:

.tests
[source,ml]
----
"eof succeed" >:: (
  fun _ctx ->
    assert_same_results Unit.print
      (None, [(), no_corr, []])
      (eof [] None no_corr no_input)
) ;
"eof fails" >:: (
  fun _ctx ->
    assert_same_results Unit.print
      (Some { where = Item (0, 'g') ;
              what = ["eof"] }, [])
      (eof [] None no_corr rest)
) ;
"eof suggests truncation" >:: (
  fun _ctx ->
    assert_same_results Unit.print
      (None, [(), correction_at (Item (0, 'g'))
                  "eof", [] ])
      (eof [] None corr rest)
) ;
----

=== First non trivial parser

The more general of parsers that do consume some input is the +cond+ parser,
which tries to recognize a condition on the next token (for instance that it
is equal to a given value). So +cond+ is a function that takes a predicate on
token and returns a parser that, when given this token, returns it (and
consumes it), or otherwise fails (with a message describing what it was
looking for).

Now that we know the type, writing the code is rather easy:

.A cond parser
[NOTE]
[source,ml]
----
let cond expl f x m e c s =
  let m = expl::m in
  ct_bind (take s) (function
    | Item (_pos, tok), s' when f tok ->
      return tok m e c s'
    | _ ->
      fail_or_maybe_not x m e c s)
----

.Parser signature
[source,ml]
----
val cond : string -> (token -> bool) -> token -> token t
----

+cond_map+ is a +cond+ that returns an optional value instead of a mere
boolean:

.Parser library: cond_map
[source,ml]
----
let cond_map expl f x m e c s =
  let m = expl::m in
  ct_bind (take s) (function
    | EndOfStream, _ ->
      fail_or_maybe_not x m e c s
    | Item (_pos, tok), s' ->
      (match f tok with
       | Some v -> return v m e c s'
       | None   -> fail_or_maybe_not x m e c s))
----

.Parser signature
[source,ml]
----
val cond_map : string -> (token -> 'b option) -> 'b -> 'b t
----

from which a simpler +cond+ parser can be written:

// TODO: a way in portia to say "replaces 'Parser library: the cond parser'"
// TODO (alt): A definition starting with same name a one that already
//             exist, followed by a coma and something should replace it in
//             the output instead of been appended to it.
.Parser library: the cond parser, revisited
[source,ml]
----
let cond expl f =
  cond_map expl (fun c -> if f c then Some c else None)
----

It is possible to build many simpler and more convenient parsers on top of
+cond+, such as +item+ which expects a specific token in the input, and
+range+ which expect anything in the given token range (assuming token
behavior in face of an inequality operator makes sense) :

.Parser library: the item parser
[source,ml]
----
let item ?what x =
  let expl =
    Option.default_delayed (fun () ->
      Printf.sprintf2 "%a" print_token x) what in
  cond expl ((=) x) x

let range a b expl =
  cond expl (fun c -> c >= a && c <= b) a
----

.Parser signature
[source,ml]
----
val item : ?what:string -> token -> token t
val range : token -> token -> string -> token t
----

.tests
[source,ml]
----
"item canonical success" >:: (
  fun _ctx ->
    assert_same_results Char.print
      (None, ['g', no_corr, List.tl rest])
      (item 'g' [] None no_corr rest)
) ;
"item canonical failure" >:: (
  fun _ctx ->
    assert_same_results Char.print
      (Some { what = ["X"] ;
              where = Item (0, 'g') }, [])
      (item 'X' [] None no_corr rest)
) ;
"item fails at EOF" >:: (
  fun _ctx ->
    assert_same_results Char.print
      (Some { what = ["g"] ;
              where = EndOfStream }, [])
      (item 'g' [] None no_corr no_input)
) ;
"item error exploration" >:: (
  fun _ctx ->
    (* Here we 'find' the item X just because we add it. *)
    assert_same_results Char.print
      (Some { what = ["X"] ;
              where = Item (0, 'g') },
       [ 'X', correction_at (Item (0, 'g')) "X",
         rest (* since we add X in front of rest *) ])
      (item 'X' [] None corr rest)
) ;
----

== Modifying parsers result

Before going too far we need to introduce functions that alter a parser result
(equivalent of map, fold, filter...) and come up with a convenient syntax for
those since they are going to be used prevalently.

.Parser library: applying a function to all results of a parser
[source,ml]
----
let map p f m e c s =
  ct_bind (p m e c s) (fun (e', results) ->
    let results' = List.map (fun (x, corr, rest) ->
      f x, corr, rest) results in
    ct_return (e', results'))
----

The order of parameters is important so that +map p f+ is itself a parser.
An infix operator makes it even more convenient:

.Parser library: infix operator for map
[source,ml]
----
let (>>:) = map
----

.Parser signature
[source,ml]
----
val map   : 'b t -> ('b -> 'd) -> 'd t
val (>>:) : 'b t -> ('b -> 'd) -> 'd t
----

== Combinators

The first combinators to consider are the succession of two given parsers and
the alternative of two parsers.

Notice that since we are now merely combining parsers we do not have to care
about error correction any more: only the base parsers need to pretend
succeeding when they fail.

The more general way to build a combinator for the succession of two parsers is
to take the first parser +p1+ and a function +f+ which, given the output of
+p1+, will return a parser +p2+ to apply to the remaining of the input stream.
Let's call this combinator +bind+ (by analogy with the type of the +bind+
operation in the monad ``design pattern''). The values of +bind p1 f+ are the
values of +p2+, +p1+ intermediary values being only meaningful to build +p2+.

.Parser library: bind
[source,ml]
----
let bind p1 f m e c s =
  (* TODO: should provide an explanation for what f does, and add this to the context when calling p2 *)
  ct_bind (p1 m e c s) (fun (e', r) ->
    (* For each possible result of p1, try to continue parsing with p2.
       Aggregate all encountered errors. *)
    List.fold_left (fun prev (x1, c', s') ->
        ct_bind prev (fun (e'', r') ->
          let p2 = f x1 in
          ct_bind (p2 m e'' c' s') (fun (e''', r'') ->
            ct_return (e''', List.rev_append r'' r')))
      ) (ct_return (e', [])) r)
----

With the conventional infix operator:

.Parser library: infix operator for bind
[source,ml]
----
let (>>=) = bind
----

.Parser signature
[source,ml]
----
val bind  : 'b t -> ('b -> 'd t) -> 'd t
val (>>=) : 'b t -> ('b -> 'd t) -> 'd t
----

Given this +bind+ combinator, the concatenation of two given parsers +p1+ and
+p2+ can be easily written as:

.Parser library: succession of two parsers
[source,ml]
----
let cons p1 p2 =
  p1 >>= (fun x1 -> p2 >>: fun x2 -> x1,x2)
----

Here, we want the final result set to be the product of each result of +p1+
with all following results of +p2+.

We'd better have a shorter infix alternative for +cons+ which is used very
often:

.Parser library: infix operator for cons
[source,ml]
----
let (++) p1 p2 = cons p1 p2
----

.Parser signature
[source,ml]
----
val cons : 'b t -> 'd t -> ('b * 'd) t
val (++) : 'b t -> 'd t -> ('b * 'd) t
----

Also, we will often discard the result of one parser. For instance when
parsing delimiters the only information is that the parser succeeds (there is
a delimiter) but there is no value to attach to that success. Also when using
the +check+ parser, which purpose is really not its return value. So here are
three variants of +cons+: one that ignores the result of +p1+, one that
ignores the result of +p2+ and one that ignore both (returning +()+):

.Parser library: other convenient infix operators
[source,ml]
----
let (+-) p1 p2 = p1 ++ p2 >>: fst
let (-+) p1 p2 = p1 ++ p2 >>: snd
let (--) p1 p2 = p1 ++ p2 >>: ignore
----

.Parser signature
[source,ml]
----
val (+-) : 'b t -> 'd t -> 'b t
val (-+) : 'b t -> 'd t -> 'd t
val (--) : 'b t -> 'd t -> unit t
----

Now let's test that we can indeed sequence parsers:

.tests
[source,ml]
----
"Can parse a sequence" >:: (
  fun _ctx ->
    let ab = stream_of_string "ab" in
    assert_same_results (Tuple2.print Char.print Char.print)
      (None, [('a', 'b'), no_corr, []])
      ((item 'a' ++ item 'b') [] None no_corr ab) ;
    assert_same_results Char.print
      (None, ['a', no_corr, []])
      ((item 'a' +- item 'b') [] None no_corr ab)
) ;
----

The next most useful combinator is the alternative:

.Parser library: alternative
[source,ml]
----
let oneof p1 p2 m e c s =
  ct_bind (p1 m e c s) (fun (e', r) ->
    ct_bind (p2 m e' c s) (fun (e'', r') ->
      ct_return (e'', List.rev_append r r')))

let (|||) = oneof
----

.Parser signature
[source,ml]
----
val oneof : 'b t -> 'b t -> 'b t
val (|||) : 'b t -> 'b t -> 'b t
----

Notice that results are really sets not list, so the order in which the
alternatives are listed does not matter.  Notice also that this is not an
exclusive alternative: if both +p1+ and +p2+ can parse then both will
contribute a result to the result set. As discussed in the beginning we do
not enforce that if +p1+ succeeds then +p2+ must fail nor the other way
around. If this is wanted though then it is easy enough to write:

.Parser library: exclusive alternative
[source,ml]
----
let either p1 p2 =
  (check (nay p2) -+ p1) ||| (check (nay p1) -+ p2)

let (|/|) = either
----

.Parser signature
[source,ml]
----
val either : 'b t -> 'b t -> 'b t
val (|/|)  : 'b t -> 'b t -> 'b t
----

With sequences and alternatives we can start writing some interesting tests:

.tests
[source,ml]
----
"any: 'a' or 'b' but not 'z'" >:: (
  fun _ctx ->
    let a_or_b = item 'a' ||| item 'b' in
    assert_same_results Char.print
      (None, ['a', no_corr, []])
      (a_or_b [] None no_corr (stream_of_string "a")) ;
    assert_same_results Char.print
      (None, ['b', no_corr, []])
      (a_or_b [] None no_corr (stream_of_string "b")) ;
    assert_same_results Char.print
      (Some { what = ["a"] ;
              where = Item (0, 'z') }, [])
      (a_or_b [] None no_corr (stream_of_string "z")) ;
    (* Here we try with corrections: we make up the requested item
       in front of the actual one (check the 2 possibilities): *)
    let z = stream_of_string "z" in
    assert_same_results Char.print
      (Some { what = ["a"] ;
              where = Item (0, 'z') },
       ['a', correction_at (Item (0, 'z')) "a", z ;
        'b', correction_at (Item (0, 'z')) "b", z])
      (a_or_b [] None corr z)
) ;
----

== Repeating parsers

Binding several parsers already gives us a way to harvest several values from
the input stream but many times what is needed is to repeat the same parser an
unspecified number of times.

Before that, a special case of repetition will prove very useful: having zero
or one occurrence of +p+:

.Parser library: zero or one
[source,ml]
----
let optional ~def p = p ||| return def
let optional_greedy ~def p = (p +- check (nay p)) ||| return def
----

The +optional_greedy+ above is to avoid terminating a parser on an optional
parser, which would result in two possible results systematically.

Indeed:

[source,ML]
----
optional p ++ optional p
----

would yield 2 equivalent results.

.Parser signature
[source,ml]
----
val optional : def:'b -> 'b t -> 'b t
val optional_greedy : def:'b -> 'b t -> 'b t
----

The +repeat+ combinator is a swiss-army knife for all variants of
repetitions, requiring a parser +p+ to succeed from +min+ to +max+ times
consecutively, with an optional additional parser +sep+ for a separator in
between +p+ occurrences.  It returns a list of all values returned by the
successive +p+.

By allowing +min+ to be +0+ (and making it the default value) we expect to
cut down on the many +optional (repeat p)+ that we would have otherwise.

.Parser library: repetition of a parser
[source,ml]
----
let rec repeat ~sep ?(min=0) ?max ?what p m e c s =
  (* TODO: do not repeat this when recursing. And make what a mandatory expl parameter as usual: *)
  let m = "repeat"::m in (* add min/max ? *)
  if max = Some 0 then (
    if min = 0 then return [] m e c s
    else ct_bind (take s) (fun (pt, _s') ->
      let m = ("Too many "^ Option.default "repetitions" what)::m in
      fail m (new_error pt m e) c s)
  ) else (
    let pred_ma = match max with None -> None
                               | Some m -> Some (m-1) in
    match min with
    | 0 ->
      (* we may stop here or continue *)
      (optional ~def:[] (repeat ~sep ~min:1 ?max ?what p)) m e c s
    | 1 ->
      (* at least one more, everything else optional *)
      ((p ++ optional ~def:[]
                 (sep -+ (repeat ~sep ~min:1 ?max:pred_ma ?what p))) >>:
        fun (x, xs) -> x::xs) m e c s
    | _ ->
      (* above that, repetition is mandatory *)
      ((p +- sep ++ repeat ~sep ~min:(min-1) ?max:pred_ma ?what p) >>:
        fun (x, xs) -> x::xs) m e c s
  )
----

Notice there are two conditions that terminate the recursion: +max+ reaching
+0+ (no more occurrences permitted) or, when +min > 0+, a failure of +p+.

Notice also that repeat builds a whole list before sending it to the next
stage.  We'd like to get away with this list which most often than not will be
mapped into something else. A variant of lazy list would likely be preferable
here (as in other places).

.Parser signature
[source,ml]
----
val repeat :
  sep:'d t -> ?min:int -> ?max:int -> ?what:string -> 'b t -> ('b list) t
----

We'd like to get away with the mandatory +sep+ parameter using a default value
of +return ()+ but that would prevent OCaml compiler to infer that since +sep+
result is consistently discarded any result type would be as good.  Simpler
example of this using the _REPL_:

----
# let f ?sep x = x ;;
val f : ?sep:'a -> 'b -> 'b = <fun>
# let f ?(sep=42) x = x;;
val f : ?sep:int -> 'a -> 'a = <fun>
----

Therefore we merely provide this short do-nothing constant parser to be used
when there is no separator:

.Parser library: none
[source,ml]
----
let none m = return () m
----

You may be surprised by this notation, either because you were expecting +let
none corr rest = return () corr rest+ or the shorter +let none = return ()+.
Refer to the <<type-generalization,section about type generalization>> if that
is the case.

.Parser signature
[source,ml]
----
val none : unit t
----

We can easily define the greedy version of +repeat+ (that is, a version that
swallows as many +p+ occurrences as present in the input stream) using check:

.(erroneous) greedy repetition
[source,ml]
----
let repeat_greedy ~sep ?min ?max ?what p =
  repeat ~sep ?min ?max ?what p +- check (nay (sep -+ p))
----

...which unfortunately fails for +min=0+ because of the separator.  We have to
be more cautious not to allow an input stream starting with +p+ before
returning +[]+:

.Parser library: greedy repetition
[source,ml]
----
let rec repeat_greedy ~sep ?min ?max ?what p =
  match min with
  | None | Some 0 ->
    repeat_greedy ~sep ~min:1 ?max ?what p |||
    (check (nay p) >>: fun () -> [])
  | min ->
    repeat ~sep ?min ?max ?what p +-
    (check (nay (sep -+ p)) >>:
    fun _ -> [])
----

.Parser signature
[source,ml]
----
val repeat_greedy :
  sep:'d t -> ?min:int -> ?max:int -> ?what:string -> 'b t -> ('b list) t
----

.tests
[source,ml]
----
"repetition: canonical successes" >:: (
  fun _ctx ->
    let assert_ok ?(greedy=false) ~sep ?min ?max rest exp =
      assert_same_results (List.print Char.print) exp
        ((if greedy then repeat_greedy else repeat)
           ~sep ?min ?max (item 'a') [] None no_corr rest) in
    let test_with_sep sep sep_len rest =
      let drop n = List.drop (1 + (n-1)*(1+sep_len)) rest in
      assert_ok ~sep rest
        (None,
         [['a';'a';'a'], no_corr, drop 3 ;
          ['a';'a'],     no_corr, drop 2 ;
          ['a'],         no_corr, drop 1 ;
          [],            no_corr, rest]) ;
      (* Same with min=2 *)
      assert_ok ~sep ~min:2 rest
        (None,
         [['a';'a';'a'], no_corr, drop 3 ;
          ['a';'a'],     no_corr, drop 2]) ;
      (* Testing max=2 *)
      assert_ok ~sep ~max:2 rest
        (None,
         [['a';'a'],     no_corr, drop 2;
          ['a'],         no_corr, drop 1;
          [],            no_corr, rest]) ;
      (* Now with min and max *)
      assert_ok ~sep ~min:1 ~max:2 rest
        (None,
         [['a';'a'],     no_corr, drop 2 ;
          ['a'],         no_corr, drop 1]) ;
      (* min = max *)
      assert_ok ~sep ~min:2 ~max:2 rest
        (None, [['a';'a'],     no_corr, drop 2]) in
    let aaab = stream_of_string "aaab"
    and a_a_a_b = stream_of_string "a_a_a_b"
    and _a_a_a_b = stream_of_string "_a_a_a_b" in
    test_with_sep none       0 aaab ;
    test_with_sep underscore 1 a_a_a_b ;
    assert_ok ~greedy:true ~sep:none aaab
      (None,
       [['a';'a';'a'], no_corr, List.drop 3 aaab]) ;
    assert_ok ~greedy:true ~sep:underscore a_a_a_b
      (None,
       [['a';'a';'a'], no_corr, List.drop 5 a_a_a_b]) ;
    (* Do not allow a separator at start *)
    assert_ok ~greedy:true ~sep:underscore _a_a_a_b
      (None, [[], no_corr, _a_a_a_b])
) ;
"repetition: simplest failure" >:: (
  fun _ctx ->
    assert_same_results (List.print Char.print)
      (Some { what = ["a"] ;
              where = Item (0, 'z') }, [])
      (repeat ~sep:none ~min:1 (item 'a') [] None no_corr (stream_of_string "zaab")) ;
    assert_same_results (List.print Char.print)
      (Some { what = ["a"] ;
              where = Item (0, 'z') }, [])
      (repeat_greedy ~sep:none ~min:1 (item 'a') [] None no_corr (stream_of_string "zaab"))
) ;
"repetition: missing separator" >:: (
  fun _ctx ->
    assert_same_results (List.print Char.print)
      (Some { what = ["-"] ;
              where = Item (3, 'a') }, [])
      (repeat ~sep:(item '-') ~min:3 (item 'a') [] None no_corr (stream_of_string "a-aab")) ;
    assert_same_results (List.print Char.print)
      (Some { what = ["-"] ;
              where = Item (3, 'a') }, [])
      (repeat_greedy ~sep:(item '-') ~min:3 (item 'a') [] None no_corr (stream_of_string "a-aab"))
) ;
"repetition: below min" >:: (
  fun _ctx ->
    assert_same_results (List.print Char.print)
      (Some { what = ["a"] ;
              where = Item (2, 'b') }, [])
      (repeat ~sep:none ~min:3 (item 'a') [] None no_corr (stream_of_string "aab")) ;
    assert_same_results (List.print Char.print)
      (Some { what = ["a"] ;
              where = Item (2, 'b') }, [])
      (repeat_greedy ~sep:none ~min:3 (item 'a') [] None no_corr (stream_of_string "aab"))
) ;
----

Some variants of +repeat+ can now be defined:

.Parser library: repeat variants
[source,ml]
----
let several ~sep = repeat ~sep ~min:1
let several_greedy ~sep = repeat_greedy ~sep ~min:1
let times n = repeat ~min:n ~max:n
----

.Parser signature
[source,ml]
----
val several : sep:'d t -> ?max:int -> ?what:string -> 'b t -> ('b list) t
val several_greedy : sep:'z t -> ?max:int -> ?what:string -> 'b t -> ('b list) t
val times : int -> sep:'z t -> ?what:string -> 'b t -> ('b list) t
----

With all these new combinators, more interesting tests can be devised:

.tests
[source,ml]
----
"several combinators bound together" >:: (
  fun _ctx ->
    let p = decimal_digit >>= (fun c ->
      let i = Char.code c - Char.code '0' in
      assert_bool "not a digit" (i >= 0 && i <= 9) ;
      (* match a sequence of i zeros *)
      times ~sep:none i (item '0')) in
    let rest1 = stream_of_string "105"
    and rest2 = stream_of_string "100"
    and rest3 = stream_of_string "30005"
    and rest4 = stream_of_string "3005" in
    assert_same_results (List.print Char.print)
      (None, [['0'], no_corr, List.drop 2 rest1])
      (p [] None no_corr rest1) ;
    assert_same_results (List.print Char.print)
      (None, [['0'], no_corr, List.drop 2 rest2])
      (p [] None no_corr rest2) ;
    assert_same_results (List.print Char.print)
      (None, [['0';'0';'0'], no_corr, List.drop 4 rest3])
      (p [] None no_corr rest3) ;
    assert_same_results (List.print Char.print)
      (Some { what = ["0"] ;
              where = Item (3, '5') }, [])
      (p [] None no_corr rest4)
) ;
----

.Parser library: trivial parsers and utilities
[source,ml]
----
let replace x _ = x

let anything m e c s =
  let m = "anything"::m in
  ct_bind (take s) (function
    | EndOfStream, _s' ->
      let m = "unexpected end of stream"::m in
      let e' = new_error EndOfStream m e in
      fail m e' c s
    | Item (_pos, tok), s' ->
      return tok m e c s')
----

Notice that +anything+ can only fail at end of input.

.Parser signature
[source,ml]
----
val replace : token -> 'b -> token
val anything : token t
----

== Miscellaneous

[[type-generalization]]
=== Type generalization

Let's get back to why we haven't defined +none+ simply as +let none = return
()+, letting automatic currying to lighten the syntax:

----
# let none = return ();;
             ^^^^^^^^^
Error: The type of this expression, ('_a, unit, '_b) t,
       contains type variables that cannot be generalized
----

This is actually a limitation of OCaml compiler. Here is what's happening:
normally, in an expression like +let name = expr+, +expr+ will be typed first,
leading in this case where +expr+ is actually +return ()+ to the type +(`_a,
unit, '_b) t+ (where +'_a+ and +'_b+ are ``weak types'' (refer to the
definition of +return+: it's merely a function of 3 parameters returning a list
of the triplet of these 3 parameters). Once +expr+ is typed, OCaml follow this
rule: if +expr+ is a function (as in +function ... ->+), a constant or an
identifier then generalize the weak types into universal types (the more
familiar +'a+, +'b+ etc). If +erpx+ is anything fancier, though, such as a
partial application as is the case here, then do not generalize.

If instead we had +let name params... = expr+ then, given it's syntactic sugar
for +let name = function ... -> expr+ then the ``weak types'' would have been
generalized.

So we have to make this looks more like a function, by making explicit at least
one parameter (a process famously known under the tickling name
``eta-expansion'').

This feels arbitrary because it is ; apparently this is one of the minor
disadvantage of a typing rules that has plenty of other advantages such as
simplifying something that's already quite complex. See
https://caml.inria.fr/resources/doc/faq/core.en.html#eta-expansion[the OCaml FAQ]
for more details.

This is unfortunately going to hit us a lot when defining parser combinators
because we'd like to get away with the many meaningless and repetitive
parameters which presence just obfuscate the intent of the code. C'est la vie.

=== Bounded set

We still have to provide an implementation for our set of fixed maximum size.
The simplest implementation is that of a list with a current size:

.ParsersBoundedSet.ml: type
[source,ml]
----
type 'a t =
  { size : int ;
    max_size : int ;
    items : 'a list }
----

With the trivial constructor:

.ParsersBoundedSet.ml: constructor
[source,ml]
----
let make max_size =
  { size = 0 ; max_size ; items = [] }
----

And the only three operations we've met so far:

.ParsersBoundedSet.ml: operations
[source,ml]
----
let is_full t = t.size >= t.max_size
let is_empty t = t.size = 0

let add t x =
  { t with size = t.size + 1 ;
           items = x::t.items }
----

It would also be convenient to provide a simple shortcut in +Parsers+ for
cases where no error detection is required:

.Parsers.ml: no error detection
[source,ml]
----
let no_error_correction = ParsersBoundedSet.make 0
----

=== Printers

If there is something annoying about OCaml it's the lack of default printers
for types. +Batteries+ provides +dump+ but it is oblivious to constructors so
the result is not pretty. So let's write our own printers.

It would be best to provide formatters instead of mere printers to benefit
from automatic typesetting but unfortunately +Batteries+ support for those is
minimal so it's better to forget about formatters to cut down on typing.

First, parser configuration must supply printers of tokens, positions and
streams:

.Parser configuration:
[source,ml]
----
val print_token : 'o BatInnerIO.output -> token -> unit
val print_position : 'o BatInnerIO.output -> position -> unit
val print_stream : 'o BatInnerIO.output -> stream -> unit
----

With a printer for +ParsersBoundedSet.t+ we could also print corrections:

.ParsersBoundedSet.ml: printer
[source,ml]
----
open Batteries

let print print_value fmt t =
  List.print print_value fmt t.items
----

.ParsersMisc.ml: printer
[source,ml]
----
open Batteries

let print_stream_item print_value fmt = function
  | EndOfStream -> String.print fmt "end of input"
  | Item c -> print_value fmt c
----

.ParsersCorrections.ml: printers
[source,ml]
----
open Batteries

let print_correction print_where fmt (pos, msg) =
  Printf.fprintf fmt "%s at %a"
    msg
    (ParsersMisc.print_stream_item print_where) pos

let print_corrections print_where fmt corr =
  ParsersBoundedSet.print (print_correction print_where) fmt corr
----

With all this we can print errors and results:

.Parser library: printers
[source,ml]
----
let print_postok fmt (pos, tok) =
  Printf.fprintf fmt "%a (near %a)"
    print_position pos
    print_token tok

let print_error_context fmt = function
  | [] ->
    String.print fmt "No context known. This is bad. Good luck!"
  | [x] ->
    Printf.fprintf fmt "Cannot find %s" x
  | x::rest ->
    let sep = " while looking for " in
    Printf.fprintf fmt "Cannot find %s%a" x
      (List.print ~first:sep ~sep String.print) rest

let print_error fmt = function
  | None -> Printf.fprintf fmt "Ok"
  | Some e ->
    Printf.fprintf fmt "Error at %a: %a"
      (ParsersMisc.print_stream_item print_postok) e.where
      print_error_context e.what

let print_possible_result print_output fmt (x, corr, rest) =
  Printf.fprintf fmt "(output=%a,corrections=%a,rest=%a)"
    print_output x
    (print_corrections print_postok) corr
    print_stream rest

let print_possible_results print_output fmt (e, r) =
  Printf.fprintf fmt "%a, %a"
    print_error e
    (List.print (print_possible_result print_output)) r

let print_result print_output fmt = function
  | Ok b -> print_output fmt b
  | Bad (Approximation (b, c)) ->
    Printf.fprintf fmt "Approximately: %a (corrections: %a)"
      print_output b
      (print_corrections print_postok) c
  | Bad (Ambiguous lst) ->
    Printf.fprintf fmt "Ambiguous: %a"
      (List.print (fun fmt (b, c) ->
        Printf.fprintf fmt "%a (corrections: %a)"
          print_output b
          (print_corrections print_postok) c)) lst
  | Bad (NoSolution e) ->
    print_error fmt e
----

.Parser signature
[source,ml]
----
val print_error : 'o BatInnerIO.output -> error option -> unit

val print_possible_result :
  ('o BatInnerIO.output -> 'b -> unit) ->
  'o BatInnerIO.output ->
  'b possible_result -> unit

val print_possible_results :
  ('o BatInnerIO.output -> 'b -> unit) ->
  'o BatInnerIO.output ->
  (error option * 'b possible_result list) -> unit

val print_result :
  ('o BatInnerIO.output -> 'b -> unit) ->
  'o BatInnerIO.output ->
  ('b, 'b failure) result -> unit
----


== Parsing usual things

It might come handy to have some ready made parsers for common things such
as words, numbers, etc... We will regroup those in a +ParsersUsual+ module
parametrized by a +Parsers+ module for characters:

.ParsersUsual.ml: Parsers for usual things
[source,ml]
----
open Batteries
module Make (P : Parsers.S with type token = char) =
struct
  open P
  (* ...usual parsers... *)
end
----

...that we will test along with the +Parsers+ module:

.other tested modules
[source,ml]
----
module SimpleUsual = ParsersUsual.Make (P)
open SimpleUsual
----

=== Strings

The more useful is probably to match some strings in the input stream:

.usual parsers: strings
[source,ml]
----
let string s =
  let rec loop i =
    if i >= String.length s then return ()
    else (
      (item ~what:s s.[i]) -- (loop (i+1))
    ) in
  loop 0
----

=== Numbers

We will try to follow the most common conventions for parsing numbers.
Notice that a simple base 10 integer number must start with a non 0
(otherwise it's octal).  We make no exception for the single digit '0' which
will be parsed as octal.

.usual parsers: integers
[source,ml]
----
type integer = Int.t (* or maybe not? *)

let decimal_digit m =
  range '0' '9' "digit" m

let non_zero_decimal_digit m =
  range '1' '9' "non-zero digit" m

let num_of_char c =
  let cc = Char.code c in
  if cc >= Char.code '0' && cc <= Char.code '9' then
    cc - Char.code '0'
  else if cc >= Char.code 'a' && cc <= Char.code 'f' then
    cc - Char.code 'a' + 10
  else if cc >= Char.code 'A' && cc <= Char.code 'F' then
    cc - Char.code 'A' + 10
  else invalid_arg "c"

let underscore m = item ~what:"underscore" '_' m

let unsigned_decimal_number m =
  let digits m = several ~sep:none decimal_digit m in
  (non_zero_decimal_digit +-
   optional ~def:' ' underscore ++
   optional ~def:[] (several ~sep:underscore digits) >>:
   fun (first, next) ->
   List.fold_left (fun c digits ->
     List.fold_left (fun c digit ->
       c * 10 + num_of_char digit) c digits) 0 ([first]::next)) m

let signed neg p =
  p                                |||
  item ~what:"sign" '+' -+ p       |||
  (item ~what:"sign" '-' -+ p >>: neg)

let decimal_number m =
  signed Int.neg unsigned_decimal_number m
----

We have made +num_of_char+ accept hexadecimal digits in foresight.

Octals, hexadecimal and binary numbers are then build similarly: a mandatory
prefix, and some digits interleaved with underscores. Notice that only the
prefix is mandatory and '0x' for instance is a valid immediate (representing
zero of course), as in perl.

.usual parsers: non decimal integers
[source,ml]
----
let non_decimal_integer base prefix digit =
  let digits m = several ~sep:none digit m in
  prefix -+ repeat ~sep:underscore ~what:"digits" digits >>:
     List.fold_left (fun c digits ->
       List.fold_left (fun c digit ->
         c * base + num_of_char digit) c digits) 0

let octal_digit m =
  range '0' '7' "octal digit" m

let octal_number m =
  (non_decimal_integer 8 (item '0') octal_digit |>
   signed Int.neg) m

let hexadecimal_digit m =
  cond "hexadecimal digit" (fun c ->
    (c >= '0' && c <= '9') ||
    (c >= 'a' && c <= 'f') ||
    (c >= 'A' && c <= 'F')) '1' m

let non_decimal_integer_prefix x =
  item '0' --
  cond "integer prefix" (fun c -> Char.lowercase c = x) x

let hexadecimal_number m =
  let prefix = non_decimal_integer_prefix 'x' in
  (non_decimal_integer 16 prefix hexadecimal_digit |>
   signed Int.neg) m

let binary_digit m =
  range '0' '1' "bit" m

let binary_number m =
  let prefix = non_decimal_integer_prefix 'b' in
  (non_decimal_integer 2 prefix binary_digit |>
   signed Int.neg) m
----

Finally, this parser can parse all kinds of integers seen so far:

.usual parsers: any integer
[source,ml]
----
let integer m =
  (decimal_number     |||
   octal_number       |||
   hexadecimal_number |||
   binary_number) m
----

.tests
[source,ml]
----
"integer immediate" >:: (
  fun _ctx ->
    [ "4", 4 ;
      "42", 42 ;
      "12345", 12345 ;
      "4_294_967_296", 4_294_967_296 ;
      "042", 0o42 ;
      "0x42", 0x42 ;
      "0X42", 0x42 ;
      "0xff", 0xff ;
      "0b10", 0b10 ;
      "0x", 0 ;
      "0x4_2", 0x4_2 ;
      "-4", -4 ;
      "+4", 4 ;
      "-042", -0o42 ;
      "+042", 0o42 ;
      "-0x42", -0x42 ;
      "-0b10", -0b10 ] |>
    List.iter (fun (input, output) ->
      assert_same_results Int.print
        (None, [output, no_corr, []])
        ((integer +- eof) [] None no_corr (stream_of_string input)))
) ;
"not decimal number immediate" >:: (
  fun _ctx ->
    [ "0_" ; "0X_" ; "_123" ; "123_" ; "12__34" ; "_" ; "_0x123" ;
      "-0_" ; "-_42" ] |>
    List.iter (fun input ->
      assert_same_results Int.print
        (None, [])
        ((integer +- eof) [] None no_corr (stream_of_string input)))
) ;
----

The syntax for floating point numbers is more _perly_.  Indeed, in additional
to the usual decimal and scientific notations, Perl allows hexadecimal floating
point, with a power of two as the exponent (and a "p" instead of an "e" to
introduce the exponent, for obvious reason).

Also, notice that you can omit either the integer or the fractional part but
not both.

.usual parsers: floating point
[source,ml]
----
let fractional_part inv_base digit =
  let digits m = several ~sep:none digit m in
  several ~sep:underscore digits >>: fun digits ->
    List.fold_left (fun c_scale digits ->
        List.fold_left (fun (c, scale) digit ->
            let n = num_of_char digit |> float_of_int in
            c +. n *. scale, scale *. inv_base
          ) c_scale digits
      ) (0., inv_base) digits |>
    fst

let unsigned_decimal_fractional m =
  let dot m = item ~what:"fractional dot" '.' m in
  ((unsigned_decimal_number +- dot ++ fractional_part 0.1 decimal_digit) |||
   (return 0 +- dot ++ fractional_part 0.1 decimal_digit)                |||
   (unsigned_decimal_number +- dot ++ return 0.) >>:
       fun (n, p) -> float_of_int n +. p
  ) m

let decimal_fractional m =
  signed Float.neg unsigned_decimal_fractional m

let decimal_scientific m =
  ((decimal_fractional |||
    (decimal_number >>: float_of_int)) +-
   cond "exponent delimiter" (fun c -> c = 'e' || c = 'E') 'e' ++
   decimal_number >>: fun (m, e) ->
     m *. Float.pow 10. (float_of_int e) (* FIXME *)
   ) m

let floating_point m =
  (decimal_fractional |||
   decimal_scientific) m
----

.tests
[source,ml]
----
"floating point notation" >:: (
  fun _ctx ->
    [ "3.14", 3.14 ;
      "-3.14", -3.14 ;
      "314e2", 31400. ;
      "314e-2", 3.14 ;
      ".1", 0.1 ;
      "1.", 1.0 ] |>
    List.iter (fun (input, output) ->
      assert_same_results Float.print
        (None, [output, no_corr, []])
        ((floating_point +- eof) [] None no_corr (stream_of_string input)))
) ;
----

And finally the parser of any immediate number:

.usual parsers: any number
[source,ml]
----
type number = Int of integer
            | Float of float
let number m =
  ((integer        >>: fun x -> Int x) |||
   (floating_point >>: fun x -> Float x)) m
----

=== Character types

It is common to check for various classes of character: blanks, numerics,
alphanumerics, newlines...

.usual parsers: character classes
[source,ml]
----
let blank m =
  cond "space" (fun c -> c = ' ' || c = '\t') ' ' m

let carriage_return m = item ~what:"carriage return" '\r' m
let new_line m = item  ~what:"new line" '\n' m

let newline m =
  (optional ~def:'\r' carriage_return -+ new_line) m

let whitespace m =
  repeat_greedy ~sep:none ~what:"whitespaces" (blank ||| newline) m

let opt_whitespace m =
  optional_greedy ~def:[] whitespace m
----

Notice we read greedily the whitespaces because we want to avoid a +whitespace
-- whitespace+ ambiguity. +optional_greedy+ is there for the same reason.

.usual parsers: more character classes
[source,ml]
----
let lowercase m = range 'a' 'z' "lowercase" m
let uppercase m = range 'A' 'Z' "uppercase" m
let letter m = (lowercase ||| uppercase) m
let alphanum m = (letter ||| decimal_digit) m
----

=== Operations

Operators are another frequent occurrence. Of course how to parse an
"operation" is likely to depend on the problem at hand, but it's still useful
to discuss them here if only to demonstrate how to deal with recursive rules.

Indeed, the straightforward way to define a parser for operations would rely on
left recursion, which a combinatoric parser can not perform. Instead, we will
have to _force_ _progress_ by defining a chain of terms and subterms in order
of precedence.

The principle of such a chain is to replace a left recursing definition such
as:

[source,ml]
----
let term m = (term +- any_binary_op ++ term) m
----

with:

[source,ml]
----
let term1 m = ((term2 +- low_precedence_op ++ term2) ||| term2) m
let term2 m = ((term3 +- higher_precedence_op ++ term3) ||| term3) m
(* etc... *)
----

Allowing recursion only after some input have been consumed:

[source,ml]
----
let rec this_is_ok m =
  (item '{' -+ this_is_ok ++ item '}') m

let rec this_is_infinite_recursion m =
  (this_is_infinite_recursion ++ anything_else) m

let rec this_is_still_infinite_recursion m =
  (check some_check ++
   this_is_still_infinite_recursion) m
----

Now this chain will always parse left side first. If +1 + 2 * 3+ will properly
be parsed as +1 + (2 * 3)+ (because the parse would fail if +term1+ consumed
only +1 + 2+), the simple +3 - 2 - 1+ would be erroneously parsed as +3 - (2 -
1)+ instead of +(3 - 2) - 1+. To help with left associative operators, we need
to group operators of same precedence and associativity and use a +repeat+
parser, which associativity we are free to choose.

Here is a +binary_ops_reducer+ parser that takes a parser for binary operators
of same associativity and precedence (here called +op+), and a parser for terms
(called +term+), and returns either the left or right associativity parser. It
is expected that the +term+ parser has higher precedence than +op+. It bears
some resemblance with +repeat+ but does not discard the output of the separator
(here: the operation) and build as a last stage the final result out of the
list of partial results, with the expected associativity.  This situation
occurs often enough in practice that it's worth having a generic solution in
the parser combinator library. It is made generic enough by the use of another
parameter, the +reduce+ function, that combines two terms and an operator
results into a value of the same type as returned by term. Notice that this may
force the user of this +binary_ops_reducer+ function to `lift` the sub-term
parser in order to return a singleton term instead (if the sub-terms and terms
do not share a common type).

.Parser library: binary operations with selected associativity
[source,ml]
----
let binary_ops_reducer ?(right_associative=false) ~op ~term ~sep ~reduce =
  term +- sep ++ repeat ~sep (op +- sep ++ term) >>:
  fun (fst, lst) -> (* lst is a list of (op result * term result) *)
    let rec loop_lst last_term = function
      | [] -> last_term
      | (op, next_term)::rest ->
        if right_associative then
          reduce last_term op (loop_lst next_term rest)
        else
          loop_lst (reduce last_term op next_term) rest
        in
    loop_lst fst lst
----

.Parser signature
[source,ml]
----
val binary_ops_reducer :
  ?right_associative:bool ->
  op:'o t ->
  term:'b t ->
  sep:unit t ->
  reduce:('b -> 'o -> 'b -> 'b) ->
  'b t
----

Let's see it in action:

.tests
[source,ml]
----
"binary_ops_reducer" >:: (
  fun _ctx ->
    let term m = (decimal_digit >>: fun c -> Term c) m in
    let op m = item '+' m in
    let reduce t1 _op t2 = Op (t1, t2) in
    [ "1+2",
        Op (Term '1', Term '2'),
        Op (Term '1', Term '2') ;
      "1+2+3",
        Op (Op (Term '1', Term '2'), Term '3'),
        Op (Term '1', Op (Term '2', Term '3')) ;
      "1+2+3+4",
        Op (Op (Op (Term '1', Term '2'), Term '3'), Term '4'),
        Op (Term '1', Op (Term '2', Op (Term '3', Term '4'))) ] |>
    List.iter (fun (input_str, exp1, exp2) ->
      (* exp1 is the expected result for left associative parsing and
         exp2 for right associative parsing. *)
      let input = stream_of_string input_str in
      assert_same_results ~msg:"left assoc." binary_ops_reducer_test_result_print
        (None, [exp1, no_corr, []])
        ((binary_ops_reducer ~op ~term ~sep:none ~reduce ~right_associative:false
          +- eof) [] None no_corr input) ;
      assert_same_results ~msg:"right assoc." binary_ops_reducer_test_result_print
        (None, [exp2, no_corr, []])
        ((binary_ops_reducer ~op ~term ~sep:none ~reduce ~right_associative:true
          +- eof) [] None no_corr input))
) ;
----

with type +binary_ops_reducer_test_result+ defined globally, as required by OCaml:

.other global functions or types for testing
[source,ml]
----
type binary_ops_reducer_test_result =
    Term of Char.t
  | Op of (binary_ops_reducer_test_result *
           binary_ops_reducer_test_result)

let rec binary_ops_reducer_test_result_print fmt = function
  | Term c ->
     Printf.fprintf fmt "%c" c
  | Op (r1, r2) ->
     Printf.fprintf fmt "(%a+%a)"
       binary_ops_reducer_test_result_print r1
       binary_ops_reducer_test_result_print r2
----

Let's also test the handling of precedence with a small calculator:

.tests
[source,ml]
----
"precedence and associativity" >:: (
  fun _ctx ->
    let value m = (decimal_digit >>: num_of_char) m in
    let reduce t1 op t2 = match op with
      | '+' -> t1+t2 | '-' -> t1-t2
      | '*' -> t1*t2 | '/' -> t1/t2
      | '^' -> int_of_float((float_of_int t1)**(float_of_int t2))
      | _ -> assert false in
    let rec left_assoc_low_prec m =
      binary_ops_reducer ~op:(item '+' ||| item '-')
                         ~term:left_assoc_high_prec
                         ~sep:none ~reduce m
    and left_assoc_high_prec m =
      binary_ops_reducer ~op:(item '*' ||| item '/')
                         ~term:right_assoc_higher_prec
                         ~sep:none ~reduce m
    and right_assoc_higher_prec m =
      binary_ops_reducer ~op:(item '^')
                         ~right_associative:true
                         ~term:left_assoc_highest_prec
                         ~sep:none ~reduce m
    and left_assoc_highest_prec m =
      (value |||
       item '(' -+ left_assoc_low_prec +- item ')') m in
    [ "0",            0 ;
      "1+2",          3 ;
      "1+2+3",        6 ;
      "1+2+3+4",     10 ;
      "5-1",          4 ;
      "5-4-1",        0 ;
      "(5-4)-1",      0 ;
      "5-(4-1)",      2 ;
      "4^3^2",   262144 ;
      "4^(3^2)", 262144 ;
      "(4^3)^2",   4096 ;
      "3*2+1",        7 ;
      "1+3*2",        7 ;
      "(1+3)*2",      8 ;
      "8/2/2",        2 ] |>
    List.iter (fun (input_str, exp) ->
      let input = stream_of_string input_str in
      assert_same_results Int.print
        (None, [exp, no_corr, []])
        ((left_assoc_low_prec +- eof) [] None no_corr input))
) ;
----

Hopefully this example shed some confidence on parsing operators with any precedence and
associativity despite using parser combinators.

== Configurations

Here are provided some +Parsers.CONFIG+ for implementing properly resumable
parsers (unlike the +SimpleConfig+ that was just good for unit tests) and a
few simple position types ɣ.

=== LWT

+LWT+ already provides a +Lwt_stream.t+ type for streams, that you would expect
to be persistent given the threading context. But actually those are
destructive, therefore useless for us.

Let's define a proper persistent stream type adapted to networking.

The stream should take its tokens from blocs chained together. Reception of a
new block should append it at the end of the list (the pointer to the +next+
block must be mutable), in such a way that when all streams are done with the
first block of the chain no more pointers point to it and it can be reclaimed
by the garbage collector.

Most of the times we will want bytes in there, but for generality we must
provide streams of token. We will therefore ask for another configuration
module providing the actual token container (maybe a +Buffer.t+, a +bytes+, an
array or any indexed container) with a +nth+ function returning the token at
some designated index. This configuration module must also provide the function
returning the (promise of a) next block (and the range we ought to parse).

.ParsersLwtConfig.ml: chained buffers of tokens
[source,ml]
----
open Batteries
open ParsersMisc

module type CONFIG = sig
  type token
  val print_token : 'o BatInnerIO.output -> token -> unit
  type buf
  val nth : buf -> int -> token
  val read_buf : unit -> (buf * int * int) option Lwt.t
end

module Make (TokConf : CONFIG) :
  Parsers.CONFIG with type token = TokConf.token
                  and type position = unit =
struct
  include TokConf
  type position = unit
  let cmp_position () () = 0
  let print_position fmt () = ignore fmt
  type block =
    { buffer : buf ;
      first : int ; (* <1> *)
      last : int ;
      mutable next_block : block option }

  type non_empty_stream =
    { block : block ;
      next : int (* <2> *) }

  type stream =
    non_empty_stream option (* <3> *)

  let print_stream fmt = function
    | None -> Printf.fprintf fmt "EOF"
    | Some _s -> Printf.fprintf fmt "TODO"

  (* ...other LwtConfig definitions... *)
end
----

<1> These first and last indexes are fixed. They tell us where in the buffer
we should start and stop reading ; this is not the stream pointer!
<2> This is the stream pointer.
<3> This option type is for being able to represent the empty stream.

Notice that the chain of blocks is not persistent (because of the mutable
next pointer) but the stream itself is: a stream can be copied and reused
later regardless of what other copies are doing.

So the stream reader can either read the next available token (wrapped into a
+ct+) or wait until the next buffer to be ready:

.other LwtConfig definitions: take next token
[source,ml]
----
let rec take = function
  | None as s ->
    Lwt.return (EndOfStream, s)
  | Some s as some_s ->
    if s.next < s.block.last then
      Lwt.return (
        Item ((), nth s.block.buffer s.next),
        Some { s with next = s.next+1 })
    else (
      match s.block.next_block with
      | Some block ->
        take (Some { block ; next = block.first })
      | None ->
----

This is the problematic case. We have to request the next block, and add it to
the chain of blocks so that other streams lagging behind us could also parse
it in the future. Notice that given +read_buf+ is a blocking operation other
threads could (and hopefully will) run while we wait. But none of those are
competing parsers : despite we use threads to freeze the parsing at no point
are we actually having more than one parsing thread ; nowhere in the library
have we spawned a new thread, and all other existing streams are in this
thread own stack. This is not to say that one can not run two parsers
simultaneously but then, of course, they will have to parse different streams.
In other words, nothing else in the running program must be calling our
+read_buf+ or we will miss some blocks. Hopefully that's obvious.

So let's call +read_buf+ and wait, confident that nothing bad will happen:

.other LwtConfig definitions: take next token from next block:
[source,ml]
----
        match%lwt read_buf () with
        | None ->
          Lwt.return (EndOfStream, some_s)
        | Some (buffer, first, last) ->
          let next_block = { buffer ; first ; last ;
                             next_block = None } in
----

Of course it costs nothing to check the above assumption:

.other LwtConfig definitions: enqueue this block for laggers and retry
[source,ml]
----
        assert (s.block.next_block = None) ;
        s.block.next_block <- Some next_block ;
        take some_s
    )
----

A few more trivial definitions are needed to fulfill +Parsers.CONFIG+:

.other LwtConfig definitions: missing bits
[source,ml]
----
type 'a ct = 'a Lwt.t
let ct_bind = Lwt.bind
let ct_return = Lwt.return
let empty_stream = None
----

Example implementation that reads bytes from a file:

.ParsersLwtConfig.ml: reading bytes from a file
[source,ml]
----
module FileReader : CONFIG =
struct
  type token = char
  let print_token fmt c =
    Printf.fprintf fmt "%C" c

  type buf = bytes
  let nth = Bytes.get
  let read_buf () =
    let max_len = 1024 in
    let buf = Bytes.create max_len in
    let%lwt r = Lwt_unix.(read stdin buf 0 max_len) in
    Lwt.return (
      if r = 0 then None
      else Some (buf, 0, r))
end
----

=== Positioning in a stream

The +take+ function from +Parsers.CONFIG+ must return the position along with
the token. Of course there is no need to actually store a position with each
token. Instead, what is needed is a function that change a function returning
only the tokens into a function returning both. Again, we need those wrapper to be
pure from side effects as we may read the stream several times ; thus we cannot
hide the required state in a closure. Instead we add the positioner state to
the stream type.

The simplest such wrapper function, that works for every type of token, just
adds the offset from the beginning of the stream:

.ParsersPositions.ml: pairing an offset with every token
[source,ml]
----
open Batteries
open ParsersMisc
module Offset (Conf : Parsers.CONFIG )
  : Parsers.CONFIG with type token = Conf.token
                    and type position = int
                    and type stream = Conf.stream * int
                    and type 'a ct = 'a Conf.ct =
struct
  (* Include all but stream type :( *)
  type token = Conf.token
  let print_token = Conf.print_token
  type 'a ct = 'a Conf.ct
  let ct_bind = Conf.ct_bind
  let ct_return = Conf.ct_return
  type stream = Conf.stream * int
  let empty_stream = Conf.empty_stream, 0
  type position = int
  let cmp_position = Int.compare
  let print_position fmt ofs =
    Printf.fprintf fmt "offset %d" ofs
  let print_stream fmt (str, _) = Conf.print_stream fmt str
  let take (stream, state) =
    ct_bind (Conf.take stream) (function
      | Item (_, tok), stream' ->
        ct_return (Item (state, tok), (stream', state+1))
      | EndOfStream, stream' ->
        ct_return (EndOfStream, (stream', state)))
end
----

Another simple wrapper keeping track of the position as number of lines and
columns must sneak at the obtained tokens (looking for newlines) and
therefore works only with streams of characters:

.ParsersPositions.ml: pairing a line number and column number with every characters
[source,ml]
----
module LineCol (Conf : Parsers.CONFIG with type token = char
                                       and type position = unit)
  : Parsers.CONFIG with type token = Conf.token
                    and type position = int * int
                    and type stream = Conf.stream * int * int * char
                    and type 'a ct = 'a Conf.ct =
struct
  type token = Conf.token
  let print_token = Conf.print_token
  type 'a ct = 'a Conf.ct
  let ct_bind = Conf.ct_bind
  let ct_return = Conf.ct_return
  type stream = Conf.stream * int * int * char
  let empty_stream =
    Conf.empty_stream, 0, 0, 'x'
  type position = int * int
  let cmp_position (l1, c1) (l2, c2) =
    match Int.compare l1 l2 with
    | 0 -> Int.compare c1 c2
    | x -> x
  let print_position fmt (line, col) =
    Printf.fprintf fmt "line %d, col %d" line col
  let print_stream fmt (str, _, _, _) = Conf.print_stream fmt str
  let take (stream, line, col, last_tok) =
    ct_bind (Conf.take stream) (function
      | Item (_, tok), stream' ->
        let line, col =
          if last_tok = '\n' then (line+1, 0)
          else (line, col+1) in
        ct_return (Item ((line, col), tok), (stream', line, col, tok))
      | EndOfStream, stream' ->
        ct_return (EndOfStream, (stream', line, col, last_tok)))
end
----

